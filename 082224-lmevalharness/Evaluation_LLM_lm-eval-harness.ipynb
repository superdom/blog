{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c131820-a28e-49a4-b791-d42c0d3cda6f",
   "metadata": {},
   "source": [
    "## Inference with koBEST Benchmark Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572ada6-37a2-43c2-a297-5eaf6fd36c1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ff3526-c2ad-42f9-b1db-cd2115cc41be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403f435d701749fd914a25a9463fdfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\", max_length=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40604c98-df23-4335-8697-d561c2534e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '콜라독립 815(815 Cola)는 코카콜라를 대한민국에서 라이선스로 만들어 오던 범양식품이 1998년 4월 1일에 출시한 탄산음료다. 질문: 콜라독립 815는 코카콜라에서 만들었나요? 답변: 콜라독립 815은 범양식품이 만든 제품입니다. 콜라독립 815은 1998년 4월 1일에 출시한 탄산음료다. 콜라독립 815의 맛은 코카콜라와 비슷하다. 콜라독립 815은 코카콜라보다 가격이 저렴하다. 콜라독립 815은 코카콜라와 같은 음료를 만들기 위해 코카콜라의 레시피를 사용했다. 콜라독립 815은 코카콜라를 대한민국에서 라이선스로 만들어 오던 범양식품이 만든 제품이다. 콜라독립 815은 코카콜라와 비슷한 음료를 만들기 위해 코카콜라의 레시피를 사용했다. 콜라독립 815은 코카콜라보다 가격이'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"콜라독립 815(815 Cola)는 코카콜라를 대한민국에서 라이선스로 만들어 오던 범양식품이 1998년 4월 1일에 출시한 탄산음료다. 질문: 콜라독립 815는 코카콜라에서 만들었나요? 답변:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cde60-0e64-4e9a-bff8-0b3a0a1e16b4",
   "metadata": {},
   "source": [
    "## Install lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa8d685-22c5-4259-b7d8-cfac7802e0fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness.git\n",
      "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git to /tmp/pip-req-build-7drezq37\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git /tmp/pip-req-build-7drezq37\n",
      "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit a4987bba6e9e9b3f22bd3a6c1ecf0abd04fd5622\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.32.1)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.20.0)\n",
      "Requirement already satisfied: jsonlines in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.8.7)\n",
      "Requirement already satisfied: peft>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.11.1)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.13.4)\n",
      "Requirement already satisfied: pytablewriter in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (1.2.0)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (1.3.1)\n",
      "Requirement already satisfied: sqlitedict in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (2.3.0+cu121)\n",
      "Requirement already satisfied: tqdm-multiprocess in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.0.11)\n",
      "Requirement already satisfied: transformers>=4.1 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (4.44.0)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.21.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (0.3.8)\n",
      "Requirement already satisfied: word2number in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (1.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.3) (10.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.3) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.8.6)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (2.1.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (3.9)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (1.16.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (2.10.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (2024.5.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (5.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.3) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1->lm_eval==0.4.3) (0.19.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonlines->lm_eval==0.4.3) (23.1.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (68.2.2)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (3.2.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.3) (0.1.6)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (1.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.3.1)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /opt/conda/lib/python3.11/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.3) (5.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8->lm_eval==0.4.3) (2.1.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.3) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.3) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.8->lm_eval==0.4.3) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/EleutherAI/lm-evaluation-harness.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9c0b2-a542-4aa0-b436-7df405ed7b57",
   "metadata": {},
   "source": [
    "## Evaluate KoBEST boolq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4fcbd6-be44-4214-9327-298ae963bac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kobest_boolq.yaml  kobest_hellaswag.yaml  kobest_wic.yaml  README.md\n",
      "kobest_copa.yaml   kobest_sentineg.yaml   __pycache__\t   utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls ./lm-evaluation-harness/lm_eval/tasks/kobest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38d6dee-fc63-4213-9736-4a84f0e7f424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:\n",
      "  - kobest\n",
      "task: kobest_boolq\n",
      "dataset_path: skt/kobest_v1\n",
      "dataset_name: boolq\n",
      "output_type: multiple_choice\n",
      "training_split: train\n",
      "validation_split: validation\n",
      "test_split: test\n",
      "doc_to_text: \"{{paragraph}} 질문: {{question}} 답변: \"\n",
      "doc_to_target: \"{{label}}\"\n",
      "doc_to_choice: [\"아니오\", \"예\"]\n",
      "metric_list:\n",
      "  - metric: acc\n",
      "    aggregation: mean\n",
      "    higher_is_better: True\n",
      "  - metric: f1\n",
      "    aggregation: !function utils.macro_f1_score\n",
      "    average: macro\n",
      "    hf_evaluate: true\n",
      "    higher_is_better: True\n",
      "metadata:\n",
      "  version: 1.0\n"
     ]
    }
   ],
   "source": [
    "!cat ./lm-evaluation-harness/lm_eval/tasks/kobest/kobest_boolq.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7af2f7c-4aba-4871-a38d-3ea87a875099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22:10:15:38,195 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2024-08-22:10:15:38,198 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2024-08-22:10:15:42,993 INFO     [__main__.py:376] Selected Tasks: ['kobest_boolq']\n",
      "2024-08-22:10:15:42,994 INFO     [evaluator.py:158] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42\n",
      "2024-08-22:10:15:42,994 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B', 'dtype': 'auto'}\n",
      "2024-08-22:10:15:43,023 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
      "2024-08-22:10:15:43,328 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:02<00:00,  1.33it/s]\n",
      "2024-08-22:10:15:47,727 WARNING  [evaluator.py:262] Overwriting default num_fewshot of kobest_boolq from None to 0\n",
      "2024-08-22:10:15:47,727 INFO     [evaluator.py:274] Setting fewshot random generator seed to 42\n",
      "2024-08-22:10:15:47,728 INFO     [task.py:423] Building contexts for kobest_boolq on rank 0...\n",
      "100%|█████████████████████████████████████| 1404/1404 [00:00<00:00, 2820.87it/s]\n",
      "2024-08-22:10:15:48,259 INFO     [evaluator.py:457] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                  | 0/2808 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Determined largest batch size: 64\n",
      "Running loglikelihood requests: 100%|███████| 2808/2808 [00:43<00:00, 65.23it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /home/jovyan)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "{\n",
      "  \"results\": {\n",
      "    \"kobest_boolq\": {\n",
      "      \"alias\": \"kobest_boolq\",\n",
      "      \"acc,none\": 0.5220797720797721,\n",
      "      \"acc_stderr,none\": 0.013335745662578474,\n",
      "      \"f1,none\": 0.3838524883403499,\n",
      "      \"f1_stderr,none\": \"N/A\"\n",
      "    }\n",
      "  },\n",
      "  \"group_subtasks\": {\n",
      "    \"kobest_boolq\": []\n",
      "  },\n",
      "  \"configs\": {\n",
      "    \"kobest_boolq\": {\n",
      "      \"task\": \"kobest_boolq\",\n",
      "      \"tag\": [\n",
      "        \"kobest\"\n",
      "      ],\n",
      "      \"dataset_path\": \"skt/kobest_v1\",\n",
      "      \"dataset_name\": \"boolq\",\n",
      "      \"training_split\": \"train\",\n",
      "      \"validation_split\": \"validation\",\n",
      "      \"test_split\": \"test\",\n",
      "      \"doc_to_text\": \"{{paragraph}} 질문: {{question}} 답변: \",\n",
      "      \"doc_to_target\": \"{{label}}\",\n",
      "      \"doc_to_choice\": [\n",
      "        \"아니오\",\n",
      "        \"예\"\n",
      "      ],\n",
      "      \"description\": \"\",\n",
      "      \"target_delimiter\": \" \",\n",
      "      \"fewshot_delimiter\": \"\\n\\n\",\n",
      "      \"num_fewshot\": 0,\n",
      "      \"metric_list\": [\n",
      "        {\n",
      "          \"metric\": \"acc\",\n",
      "          \"aggregation\": \"mean\",\n",
      "          \"higher_is_better\": true\n",
      "        },\n",
      "        {\n",
      "          \"metric\": \"f1\",\n",
      "          \"aggregation\": \"def macro_f1_score(items):\\n    from sklearn.metrics import f1_score\\n\\n    unzipped_list = list(zip(*items))\\n    golds = unzipped_list[0]\\n    preds = unzipped_list[1]\\n    fscore = f1_score(golds, preds, average=\\\"macro\\\")\\n    return fscore\\n\",\n",
      "          \"average\": \"macro\",\n",
      "          \"hf_evaluate\": true,\n",
      "          \"higher_is_better\": true\n",
      "        }\n",
      "      ],\n",
      "      \"output_type\": \"multiple_choice\",\n",
      "      \"repeats\": 1,\n",
      "      \"should_decontaminate\": false,\n",
      "      \"metadata\": {\n",
      "        \"version\": 1.0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"versions\": {\n",
      "    \"kobest_boolq\": 1.0\n",
      "  },\n",
      "  \"n-shot\": {\n",
      "    \"kobest_boolq\": 0\n",
      "  },\n",
      "  \"higher_is_better\": {\n",
      "    \"kobest_boolq\": {\n",
      "      \"acc\": true,\n",
      "      \"f1\": true\n",
      "    }\n",
      "  },\n",
      "  \"n-samples\": {\n",
      "    \"kobest_boolq\": {\n",
      "      \"original\": 1404,\n",
      "      \"effective\": 1404\n",
      "    }\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"model\": \"hf\",\n",
      "    \"model_args\": \"pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto\",\n",
      "    \"model_num_parameters\": 8030261248,\n",
      "    \"model_dtype\": \"torch.bfloat16\",\n",
      "    \"model_revision\": \"main\",\n",
      "    \"model_sha\": \"48d6d0fc4e02fb1269b36940650a1b7233035cbb\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"batch_sizes\": [\n",
      "      64\n",
      "    ],\n",
      "    \"device\": \"cuda:0\",\n",
      "    \"use_cache\": null,\n",
      "    \"limit\": null,\n",
      "    \"bootstrap_iters\": 100000,\n",
      "    \"gen_kwargs\": null,\n",
      "    \"random_seed\": 42,\n",
      "    \"numpy_seed\": 42,\n",
      "    \"torch_seed\": 42,\n",
      "    \"fewshot_seed\": 42\n",
      "  },\n",
      "  \"git_hash\": null,\n",
      "  \"date\": 1724321742.9935772,\n",
      "  \"pretty_env_info\": \"PyTorch version: 2.3.0+cu121\\nIs debug build: False\\nCUDA used to build PyTorch: 12.1\\nROCM used to build PyTorch: N/A\\n\\nOS: Ubuntu 22.04.3 LTS (x86_64)\\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\\nClang version: Could not collect\\nCMake version: Could not collect\\nLibc version: glibc-2.35\\n\\nPython version: 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0] (64-bit runtime)\\nPython platform: Linux-6.5.0-1024-azure-x86_64-with-glibc2.35\\nIs CUDA available: True\\nCUDA runtime version: Could not collect\\nCUDA_MODULE_LOADING set to: LAZY\\nGPU models and configuration: GPU 0: NVIDIA A100 80GB PCIe\\nNvidia driver version: 535.183.01\\ncuDNN version: Could not collect\\nHIP runtime version: N/A\\nMIOpen runtime version: N/A\\nIs XNNPACK available: True\\n\\nCPU:\\nArchitecture:                       x86_64\\nCPU op-mode(s):                     32-bit, 64-bit\\nAddress sizes:                      48 bits physical, 48 bits virtual\\nByte Order:                         Little Endian\\nCPU(s):                             24\\nOn-line CPU(s) list:                0-23\\nVendor ID:                          AuthenticAMD\\nModel name:                         AMD EPYC 7V13 64-Core Processor\\nCPU family:                         25\\nModel:                              1\\nThread(s) per core:                 1\\nCore(s) per socket:                 24\\nSocket(s):                          1\\nStepping:                           1\\nBogoMIPS:                           4890.88\\nFlags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl tsc_reliable nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext perfctr_core invpcid_single vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves clzero xsaveerptr rdpru arat umip vaes vpclmulqdq rdpid fsrm\\nHypervisor vendor:                  Microsoft\\nVirtualization type:                full\\nL1d cache:                          768 KiB (24 instances)\\nL1i cache:                          768 KiB (24 instances)\\nL2 cache:                           12 MiB (24 instances)\\nL3 cache:                           96 MiB (3 instances)\\nNUMA node(s):                       1\\nNUMA node0 CPU(s):                  0-23\\nVulnerability Gather data sampling: Not affected\\nVulnerability Itlb multihit:        Not affected\\nVulnerability L1tf:                 Not affected\\nVulnerability Mds:                  Not affected\\nVulnerability Meltdown:             Not affected\\nVulnerability Mmio stale data:      Not affected\\nVulnerability Retbleed:             Not affected\\nVulnerability Spec rstack overflow: Vulnerable: Safe RET, no microcode\\nVulnerability Spec store bypass:    Vulnerable\\nVulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\nVulnerability Spectre v2:           Mitigation; Retpolines; STIBP disabled; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected\\nVulnerability Srbds:                Not affected\\nVulnerability Tsx async abort:      Not affected\\n\\nVersions of relevant libraries:\\n[pip3] numpy==1.24.4\\n[pip3] torch==2.3.0+cu121\\n[pip3] torchaudio==2.3.0+cu121\\n[pip3] torchvision==0.18.0+cu121\\n[pip3] triton==2.3.0\\n[conda] nomkl                     1.0                  h5ca1d4c_0    conda-forge\\n[conda] numpy                     1.24.4          py311h64a7726_0    conda-forge\\n[conda] torch                     2.3.0+cu121              pypi_0    pypi\\n[conda] torchaudio                2.3.0+cu121              pypi_0    pypi\\n[conda] torchvision               0.18.0+cu121             pypi_0    pypi\\n[conda] triton                    2.3.0                    pypi_0    pypi\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"upper_git_hash\": null,\n",
      "  \"tokenizer_pad_token\": [\n",
      "    \"<|end_of_text|>\",\n",
      "    \"128001\"\n",
      "  ],\n",
      "  \"tokenizer_eos_token\": [\n",
      "    \"<|end_of_text|>\",\n",
      "    \"128001\"\n",
      "  ],\n",
      "  \"tokenizer_bos_token\": [\n",
      "    \"<|begin_of_text|>\",\n",
      "    \"128000\"\n",
      "  ],\n",
      "  \"eot_token_id\": 128001,\n",
      "  \"max_length\": 131072\n",
      "}\n",
      "2024-08-22:10:16:39,907 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
      "2024-08-22:10:16:39,908 INFO     [evaluation_tracker.py:287] Saving per-sample results for: kobest_boolq\n",
      "hf (pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: auto (64)\n",
      "|   Tasks    |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|------------|------:|------|-----:|------|---|-----:|---|------|\n",
      "|kobest_boolq|      1|none  |     0|acc   |↑  |0.5221|±  |0.0133|\n",
      "|            |       |none  |     0|f1    |↑  |0.3839|±  |   N/A|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto \\\n",
    "    --tasks kobest_boolq \\\n",
    "    --num_fewshot 0 \\\n",
    "    --seed 42 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto\\\n",
    "    --output_path ./eval_llama31-8B/kobest/boolq/0-shot \\\n",
    "    --log_samples \\\n",
    "    --show_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0c38f7-f5e8-4f56-8d29-3a723d0c0b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2024-08-22T10-16-39.908535.json\n",
      "samples_kobest_boolq_2024-08-22T10-16-39.908535.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./eval_llama31-8B/kobest/boolq/0-shot/meta-llama__Meta-Llama-3.1-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b143fd0f-bac3-469a-9395-d7222c1eb9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"doc_id\": 0, \"doc\": {\"paragraph\": \"콜라독립 815(815 Cola)는 코카콜라를 대한민국에서 라이선스로 만들어 오던 범양식품이 1998년 4월 1일에 출시한 탄산음료다.\", \"question\": \"콜라독립 815는 코카콜라에서 만들었나요?\", \"label\": 0}, \"target\": \"0\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"콜라독립 815(815 Cola)는 코카콜라를 대한민국에서 라이선스로 만들어 오던 범양식품이 1998년 4월 1일에 출시한 탄산음료다. 질문: 콜라독립 815는 코카콜라에서 만들었나요? 답변: \", \"arg_1\": \" 아니오\"}, \"gen_args_1\": {\"arg_0\": \"콜라독립 815(815 Cola)는 코카콜라를 대한민국에서 라이선스로 만들어 오던 범양식품이 1998년 4월 1일에 출시한 탄산음료다. 질문: 콜라독립 815는 코카콜라에서 만들었나요? 답변: \", \"arg_1\": \" 예\"}}, \"resps\": [[[\"-14.689537048339844\", \"False\"]], [[\"-15.082908630371094\", \"False\"]]], \"filtered_resps\": [[\"-14.689537048339844\", \"False\"], [\"-15.082908630371094\", \"False\"]], \"doc_hash\": \"821038daf427b97b5fb456244a774a9a8585275803d8dfe2747d18ae34574dce\", \"prompt_hash\": \"43134ceb9b23f5061fefdfced4926c5aca808acccd8447e684440e1fd4ec844f\", \"target_hash\": \"5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91b46729d73a27fb57e9\", \"acc\": 1.0, \"f1\": [0, 0]}\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 ./eval_llama31-8B/kobest/boolq/0-shot/meta-llama__Meta-Llama-3.1-8B/samples_kobest_boolq_2024-08-22T10-16-39.908535.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d5b7c-28dc-4b95-aed8-7b5b664eb2a9",
   "metadata": {},
   "source": [
    "## Evaluate KMMLU direct_food_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8a339d-9b79-4dee-a940-7b92397e800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_direct_kmmlu_yaml\n",
      "kmmlu_direct_accounting.yaml\n",
      "kmmlu_direct_agricultural_sciences.yaml\n",
      "kmmlu_direct_aviation_engineering_and_maintenance.yaml\n",
      "kmmlu_direct_biology.yaml\n",
      "kmmlu_direct_chemical_engineering.yaml\n",
      "kmmlu_direct_chemistry.yaml\n",
      "kmmlu_direct_civil_engineering.yaml\n",
      "kmmlu_direct_computer_science.yaml\n",
      "kmmlu_direct_construction.yaml\n",
      "kmmlu_direct_criminal_law.yaml\n",
      "kmmlu_direct_ecology.yaml\n",
      "kmmlu_direct_economics.yaml\n",
      "kmmlu_direct_education.yaml\n",
      "kmmlu_direct_electrical_engineering.yaml\n",
      "kmmlu_direct_electronics_engineering.yaml\n",
      "kmmlu_direct_energy_management.yaml\n",
      "kmmlu_direct_environmental_science.yaml\n",
      "kmmlu_direct_fashion.yaml\n",
      "kmmlu_direct_food_processing.yaml\n",
      "kmmlu_direct_gas_technology_and_engineering.yaml\n",
      "kmmlu_direct_geomatics.yaml\n",
      "kmmlu_direct_health.yaml\n",
      "kmmlu_direct_industrial_engineer.yaml\n",
      "kmmlu_direct_information_technology.yaml\n",
      "kmmlu_direct_interior_architecture_and_design.yaml\n",
      "kmmlu_direct_korean_history.yaml\n",
      "kmmlu_direct_law.yaml\n",
      "kmmlu_direct_machine_design_and_manufacturing.yaml\n",
      "kmmlu_direct_management.yaml\n",
      "kmmlu_direct_maritime_engineering.yaml\n",
      "kmmlu_direct_marketing.yaml\n",
      "kmmlu_direct_materials_engineering.yaml\n",
      "kmmlu_direct_math.yaml\n",
      "kmmlu_direct_mechanical_engineering.yaml\n",
      "kmmlu_direct_nondestructive_testing.yaml\n",
      "kmmlu_direct_patent.yaml\n",
      "kmmlu_direct_political_science_and_sociology.yaml\n",
      "kmmlu_direct_psychology.yaml\n",
      "kmmlu_direct_public_safety.yaml\n",
      "kmmlu_direct_railway_and_automotive_engineering.yaml\n",
      "kmmlu_direct_real_estate.yaml\n",
      "kmmlu_direct_refrigerating_machinery.yaml\n",
      "kmmlu_direct_social_welfare.yaml\n",
      "kmmlu_direct_taxation.yaml\n",
      "kmmlu_direct_telecommunications_and_wireless_technology.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls ./lm-evaluation-harness/lm_eval/tasks/kmmlu/direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd330a75-85c7-49e0-a761-9637e45c2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:\n",
      "    - kmmlu\n",
      "    - kmmlu_direct\n",
      "dataset_path: HAERAE-HUB/KMMLU\n",
      "output_type: generate_until\n",
      "test_split: test\n",
      "fewshot_split: dev\n",
      "doc_to_text: \"{{question.strip()}}\\nA. {{A}}\\nB. {{B}}\\nC. {{C}}\\nD. {{D}}\\n정답：\"\n",
      "doc_to_target: \"{{['A', 'B', 'C', 'D'][answer-1]}}\"\n",
      "metric_list:\n",
      "  - metric: exact_match\n",
      "    aggregation: mean\n",
      "    higher_is_better: true\n",
      "    ignore_case: true\n",
      "    ignore_punctuation: true\n",
      "    regexes_to_ignore:\n",
      "          - \" \"\n",
      "generation_kwargs:\n",
      "  until:\n",
      "    - \"Q:\"\n",
      "    - \"\\n\\n\"\n",
      "    - \"</s>\"\n",
      "    - \".\"\n",
      "  do_sample: false\n",
      "  temperature: 0.0\n",
      "metadata:\n",
      "  version: 2.0\n"
     ]
    }
   ],
   "source": [
    "!cat ./lm-evaluation-harness/lm_eval/tasks/kmmlu/direct/_direct_kmmlu_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d7c916-395b-4575-8dbc-57540ef56a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22:10:17:32,309 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2024-08-22:10:17:32,311 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2024-08-22:10:17:37,468 INFO     [__main__.py:376] Selected Tasks: ['kmmlu_direct_food_processing']\n",
      "2024-08-22:10:17:37,470 INFO     [evaluator.py:158] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42\n",
      "2024-08-22:10:17:37,470 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B', 'dtype': 'auto'}\n",
      "2024-08-22:10:17:37,516 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
      "2024-08-22:10:17:37,803 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:02<00:00,  1.36it/s]\n",
      "2024-08-22:10:17:41,932 WARNING  [evaluator.py:262] Overwriting default num_fewshot of kmmlu_direct_food_processing from None to 0\n",
      "2024-08-22:10:17:41,932 INFO     [evaluator.py:274] Setting fewshot random generator seed to 42\n",
      "2024-08-22:10:17:41,933 INFO     [task.py:423] Building contexts for kmmlu_direct_food_processing on rank 0...\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1451.06it/s]\n",
      "2024-08-22:10:17:42,668 INFO     [evaluator.py:457] Running generate_until requests\n",
      "Running generate_until requests:   0%|                 | 0/1000 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Determined Largest batch size: 1\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Running generate_until requests: 100%|██████| 1000/1000 [19:40<00:00,  1.18s/it]\n",
      "fatal: not a git repository (or any parent up to mount point /home/jovyan)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "{\n",
      "  \"results\": {\n",
      "    \"kmmlu_direct_food_processing\": {\n",
      "      \"alias\": \"kmmlu_direct_food_processing\",\n",
      "      \"exact_match,none\": 0.007,\n",
      "      \"exact_match_stderr,none\": 0.0026377941462437794\n",
      "    }\n",
      "  },\n",
      "  \"group_subtasks\": {\n",
      "    \"kmmlu_direct_food_processing\": []\n",
      "  },\n",
      "  \"configs\": {\n",
      "    \"kmmlu_direct_food_processing\": {\n",
      "      \"task\": \"kmmlu_direct_food_processing\",\n",
      "      \"tag\": [\n",
      "        \"kmmlu\",\n",
      "        \"kmmlu_direct\"\n",
      "      ],\n",
      "      \"dataset_path\": \"HAERAE-HUB/KMMLU\",\n",
      "      \"dataset_name\": \"Food-Processing\",\n",
      "      \"test_split\": \"test\",\n",
      "      \"fewshot_split\": \"dev\",\n",
      "      \"doc_to_text\": \"{{question.strip()}}\\nA. {{A}}\\nB. {{B}}\\nC. {{C}}\\nD. {{D}}\\n정답：\",\n",
      "      \"doc_to_target\": \"{{['A', 'B', 'C', 'D'][answer-1]}}\",\n",
      "      \"description\": \"\",\n",
      "      \"target_delimiter\": \" \",\n",
      "      \"fewshot_delimiter\": \"\\n\\n\",\n",
      "      \"num_fewshot\": 0,\n",
      "      \"metric_list\": [\n",
      "        {\n",
      "          \"metric\": \"exact_match\",\n",
      "          \"aggregation\": \"mean\",\n",
      "          \"higher_is_better\": true,\n",
      "          \"ignore_case\": true,\n",
      "          \"ignore_punctuation\": true,\n",
      "          \"regexes_to_ignore\": [\n",
      "            \" \"\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"output_type\": \"generate_until\",\n",
      "      \"generation_kwargs\": {\n",
      "        \"until\": [\n",
      "          \"Q:\",\n",
      "          \"\\n\\n\",\n",
      "          \"</s>\",\n",
      "          \".\"\n",
      "        ],\n",
      "        \"do_sample\": false,\n",
      "        \"temperature\": 0.0\n",
      "      },\n",
      "      \"repeats\": 1,\n",
      "      \"should_decontaminate\": false,\n",
      "      \"metadata\": {\n",
      "        \"version\": 2.0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"versions\": {\n",
      "    \"kmmlu_direct_food_processing\": 2.0\n",
      "  },\n",
      "  \"n-shot\": {\n",
      "    \"kmmlu_direct_food_processing\": 0\n",
      "  },\n",
      "  \"higher_is_better\": {\n",
      "    \"kmmlu_direct_food_processing\": {\n",
      "      \"exact_match\": true\n",
      "    }\n",
      "  },\n",
      "  \"n-samples\": {\n",
      "    \"kmmlu_direct_food_processing\": {\n",
      "      \"original\": 1000,\n",
      "      \"effective\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"model\": \"hf\",\n",
      "    \"model_args\": \"pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto\",\n",
      "    \"model_num_parameters\": 8030261248,\n",
      "    \"model_dtype\": \"torch.bfloat16\",\n",
      "    \"model_revision\": \"main\",\n",
      "    \"model_sha\": \"48d6d0fc4e02fb1269b36940650a1b7233035cbb\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"batch_sizes\": [],\n",
      "    \"device\": \"cuda:0\",\n",
      "    \"use_cache\": null,\n",
      "    \"limit\": null,\n",
      "    \"bootstrap_iters\": 100000,\n",
      "    \"gen_kwargs\": null,\n",
      "    \"random_seed\": 42,\n",
      "    \"numpy_seed\": 42,\n",
      "    \"torch_seed\": 42,\n",
      "    \"fewshot_seed\": 42\n",
      "  },\n",
      "  \"git_hash\": null,\n",
      "  \"date\": 1724321857.4688764,\n",
      "  \"pretty_env_info\": \"PyTorch version: 2.3.0+cu121\\nIs debug build: False\\nCUDA used to build PyTorch: 12.1\\nROCM used to build PyTorch: N/A\\n\\nOS: Ubuntu 22.04.3 LTS (x86_64)\\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\\nClang version: Could not collect\\nCMake version: Could not collect\\nLibc version: glibc-2.35\\n\\nPython version: 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0] (64-bit runtime)\\nPython platform: Linux-6.5.0-1024-azure-x86_64-with-glibc2.35\\nIs CUDA available: True\\nCUDA runtime version: Could not collect\\nCUDA_MODULE_LOADING set to: LAZY\\nGPU models and configuration: GPU 0: NVIDIA A100 80GB PCIe\\nNvidia driver version: 535.183.01\\ncuDNN version: Could not collect\\nHIP runtime version: N/A\\nMIOpen runtime version: N/A\\nIs XNNPACK available: True\\n\\nCPU:\\nArchitecture:                       x86_64\\nCPU op-mode(s):                     32-bit, 64-bit\\nAddress sizes:                      48 bits physical, 48 bits virtual\\nByte Order:                         Little Endian\\nCPU(s):                             24\\nOn-line CPU(s) list:                0-23\\nVendor ID:                          AuthenticAMD\\nModel name:                         AMD EPYC 7V13 64-Core Processor\\nCPU family:                         25\\nModel:                              1\\nThread(s) per core:                 1\\nCore(s) per socket:                 24\\nSocket(s):                          1\\nStepping:                           1\\nBogoMIPS:                           4890.88\\nFlags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl tsc_reliable nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext perfctr_core invpcid_single vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves clzero xsaveerptr rdpru arat umip vaes vpclmulqdq rdpid fsrm\\nHypervisor vendor:                  Microsoft\\nVirtualization type:                full\\nL1d cache:                          768 KiB (24 instances)\\nL1i cache:                          768 KiB (24 instances)\\nL2 cache:                           12 MiB (24 instances)\\nL3 cache:                           96 MiB (3 instances)\\nNUMA node(s):                       1\\nNUMA node0 CPU(s):                  0-23\\nVulnerability Gather data sampling: Not affected\\nVulnerability Itlb multihit:        Not affected\\nVulnerability L1tf:                 Not affected\\nVulnerability Mds:                  Not affected\\nVulnerability Meltdown:             Not affected\\nVulnerability Mmio stale data:      Not affected\\nVulnerability Retbleed:             Not affected\\nVulnerability Spec rstack overflow: Vulnerable: Safe RET, no microcode\\nVulnerability Spec store bypass:    Vulnerable\\nVulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\nVulnerability Spectre v2:           Mitigation; Retpolines; STIBP disabled; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected\\nVulnerability Srbds:                Not affected\\nVulnerability Tsx async abort:      Not affected\\n\\nVersions of relevant libraries:\\n[pip3] numpy==1.24.4\\n[pip3] torch==2.3.0+cu121\\n[pip3] torchaudio==2.3.0+cu121\\n[pip3] torchvision==0.18.0+cu121\\n[pip3] triton==2.3.0\\n[conda] nomkl                     1.0                  h5ca1d4c_0    conda-forge\\n[conda] numpy                     1.24.4          py311h64a7726_0    conda-forge\\n[conda] torch                     2.3.0+cu121              pypi_0    pypi\\n[conda] torchaudio                2.3.0+cu121              pypi_0    pypi\\n[conda] torchvision               0.18.0+cu121             pypi_0    pypi\\n[conda] triton                    2.3.0                    pypi_0    pypi\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"upper_git_hash\": null,\n",
      "  \"tokenizer_pad_token\": [\n",
      "    \"<|end_of_text|>\",\n",
      "    \"128001\"\n",
      "  ],\n",
      "  \"tokenizer_eos_token\": [\n",
      "    \"<|end_of_text|>\",\n",
      "    \"128001\"\n",
      "  ],\n",
      "  \"tokenizer_bos_token\": [\n",
      "    \"<|begin_of_text|>\",\n",
      "    \"128000\"\n",
      "  ],\n",
      "  \"eot_token_id\": 128001,\n",
      "  \"max_length\": 131072\n",
      "}\n",
      "2024-08-22:10:37:31,529 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
      "2024-08-22:10:37:31,531 INFO     [evaluation_tracker.py:287] Saving per-sample results for: kmmlu_direct_food_processing\n",
      "hf (pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: auto\n",
      "|           Tasks            |Version|Filter|n-shot|  Metric   |   |Value|   |Stderr|\n",
      "|----------------------------|------:|------|-----:|-----------|---|----:|---|-----:|\n",
      "|kmmlu_direct_food_processing|      2|none  |     0|exact_match|↑  |0.007|±  |0.0026|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto \\\n",
    "    --tasks kmmlu_direct_food_processing \\\n",
    "    --num_fewshot 0 \\\n",
    "    --seed 42 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto\\\n",
    "    --output_path ./eval_llama31-8B/kmmlu/direct_food_processing/0-shot \\\n",
    "    --log_samples \\\n",
    "    --show_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a44ced-3245-4990-ae87-51a6690e29f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2024-08-22T10-37-31.530806.json\n",
      "samples_kmmlu_direct_food_processing_2024-08-22T10-37-31.530806.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./eval_llama31-8B/kmmlu/direct_food_processing/0-shot/meta-llama__Meta-Llama-3.1-8B/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea26cad6-99d2-44c9-a825-79ac00d03e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"doc_id\": 0, \"doc\": {\"question\": \"산성암, 중성암, 염기성암의 분류기분이 되는 것은?\", \"answer\": 2, \"A\": \"SiO2\", \"B\": \"Al2O3\", \"C\": \"P2O5\", \"D\": \"Fe2O3\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0435}, \"target\": \"B\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"산성암, 중성암, 염기성암의 분류기분이 되는 것은?\\nA. SiO2\\nB. Al2O3\\nC. P2O5\\nD. Fe2O3\\n정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"A\\n해설：SiO2의 함량이 52% 이상인 것은 중성암, 52% 미만인 것은 염기성암, 52% 이상인 것은 중성암, 52% 미만인 것은 염기성암이다\"]], \"filtered_resps\": [\"A\\n해설：SiO2의 함량이 52% 이상인 것은 중성암, 52% 미만인 것은 염기성암, 52% 이상인 것은 중성암, 52% 미만인 것은 염기성암이다\"], \"doc_hash\": \"139b202ef728343bfaa798fae16ca033d6ff3cced5c0243ebd7fae6d4e99e0d5\", \"prompt_hash\": \"70463d87a5f8877b36f1402a45a5d56a498cc7eaadb67fbb6e9faadddde1e5ab\", \"target_hash\": \"df7e70e5021544f4834bbee64a9e3789febc4be81470df629cad6ddb03320a5c\", \"exact_match\": 0.0}\n",
      "{\"doc_id\": 1, \"doc\": {\"question\": \"어류의 생식선 자극 호르몬에 대한 설명 중 바르게 된 것은?\", \"answer\": 3, \"A\": \"뇌하수체의 전엽단부의 대부분을 차지하며, 에리드로신에 잘 염색되는 세포에서 생산, 분비된다.\", \"B\": \"어류의 간신선을 자극하여 코티졸이나 코티존의 생산, 분비를 촉진한다.\", \"C\": \"뇌하수체 전엽주부에서 생산, 분비되고 당단백질을 함유한 과립을 세포질 가운데 많이 가진다.\", \"D\": \"뇌하수체 중엽에서 생산, 분비되는 호르몬이다.\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0588}, \"target\": \"C\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"어류의 생식선 자극 호르몬에 대한 설명 중 바르게 된 것은?\\nA. 뇌하수체의 전엽단부의 대부분을 차지하며, 에리드로신에 잘 염색되는 세포에서 생산, 분비된다.\\nB. 어류의 간신선을 자극하여 코티졸이나 코티존의 생산, 분비를 촉진한다.\\nC. 뇌하수체 전엽주부에서 생산, 분비되고 당단백질을 함유한 과립을 세포질 가운데 많이 가진다.\\nD. 뇌하수체 중엽에서 생산, 분비되는 호르몬이다.\\n정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"C\\n해설：어류의 생식선 자극 호르몬은 뇌하수체 전엽주부에서 생산, 분비되는 호르몬이다\"]], \"filtered_resps\": [\"C\\n해설：어류의 생식선 자극 호르몬은 뇌하수체 전엽주부에서 생산, 분비되는 호르몬이다\"], \"doc_hash\": \"c2a17f8a42822239d828fa1819c221c589aad977123235ba3ddfca0a2803caf4\", \"prompt_hash\": \"b55b3d280d46b60536eed13ae5faeb0cda47a542b8c453ed91412f22e3852d69\", \"target_hash\": \"6b23c0d5f35d1b11f9b683f0b0a617355deb11277d91ae091d399c655b87940d\", \"exact_match\": 0.0}\n",
      "{\"doc_id\": 2, \"doc\": {\"question\": \"광합성에서의 ATP 생성은 광인산화(photophosphorylation)에 의해 생성된다. 광인산화에 관한 설명 중 옳은 것은?\", \"answer\": 2, \"A\": \"미토콘드리아내막에서 일어난다.\", \"B\": \"광인산화는 전자전달과 짝지어져 일어난다.\", \"C\": \"미토콘드리아의 산화적 인산화 반응과 다른 분자 메카니즘으로 일어난다.\", \"D\": \"ATP는 비순환적 인산화(noncyclic photophosphorylatio-n photophosphorylation)에 의해서만 생성된다.\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0588}, \"target\": \"B\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"광합성에서의 ATP 생성은 광인산화(photophosphorylation)에 의해 생성된다. 광인산화에 관한 설명 중 옳은 것은?\\nA. 미토콘드리아내막에서 일어난다.\\nB. 광인산화는 전자전달과 짝지어져 일어난다.\\nC. 미토콘드리아의 산화적 인산화 반응과 다른 분자 메카니즘으로 일어난다.\\nD. ATP는 비순환적 인산화(noncyclic photophosphorylatio-n photophosphorylation)에 의해서만 생성된다.\\n정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"B\\n해설：비순환적 인산화는 전자전달과 짝지어져 일어난다\"]], \"filtered_resps\": [\"B\\n해설：비순환적 인산화는 전자전달과 짝지어져 일어난다\"], \"doc_hash\": \"b422673dbae842c1014580b71319b4927aaca0a54627c753eb493958c19f4c06\", \"prompt_hash\": \"214c35bca77fbe2d931520582bf2bb0b2ba2870a8e0c617f10c03d102d263786\", \"target_hash\": \"df7e70e5021544f4834bbee64a9e3789febc4be81470df629cad6ddb03320a5c\", \"exact_match\": 0.0}\n",
      "{\"doc_id\": 3, \"doc\": {\"question\": \"구상흑연주철에서 페라이트가 석출한 페라이트형 주철의 생성은 어느 경우에 발생되는가?\", \"answer\": 3, \"A\": \"냉각속도가 빠를 때\", \"B\": \"Mn 첨가량이 많을 때\", \"C\": \"C, Si 특히 Si가 많을 때\", \"D\": \"담금질 및 뜨임 하였을 때\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0625}, \"target\": \"C\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"구상흑연주철에서 페라이트가 석출한 페라이트형 주철의 생성은 어느 경우에 발생되는가?\\nA. 냉각속도가 빠를 때\\nB. Mn 첨가량이 많을 때\\nC. C, Si 특히 Si가 많을 때\\nD. 담금질 및 뜨임 하였을 때\\n정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"C\\n해설：주철의 페라이트형 주철은 C, Si 특히 Si가 많을 때 발생한다\"]], \"filtered_resps\": [\"C\\n해설：주철의 페라이트형 주철은 C, Si 특히 Si가 많을 때 발생한다\"], \"doc_hash\": \"9daf78762cfd784a5315f5fec74f416c68a1e82567ed8a49d777fd41ec654118\", \"prompt_hash\": \"07fed6a8686532d328e54d61ddf703dbff94e39fce76e099889a3475a7fc435f\", \"target_hash\": \"6b23c0d5f35d1b11f9b683f0b0a617355deb11277d91ae091d399c655b87940d\", \"exact_match\": 0.0}\n",
      "{\"doc_id\": 4, \"doc\": {\"question\": \"유기산 발효 중 직접산화발효가 아닌 것은?\", \"answer\": 4, \"A\": \"Acetic acid 발효\", \"B\": \"5-ketogluconic acid 발효\", \"C\": \"Gluconic acid 발효\", \"D\": \"Fumaric acid 발효\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0625}, \"target\": \"D\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"유기산 발효 중 직접산화발효가 아닌 것은?\\nA. Acetic acid 발효\\nB. 5-ketogluconic acid 발효\\nC. Gluconic acid 발효\\nD. Fumaric acid 발효\\n정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"C\\n해설：글루코닉산 발효는 직접산화발효가 아닌 발효이다\"]], \"filtered_resps\": [\"C\\n해설：글루코닉산 발효는 직접산화발효가 아닌 발효이다\"], \"doc_hash\": \"e18aaeb7c162ee981120d0aa5929e5020daa617a501d26031b6b20b8a3eb0381\", \"prompt_hash\": \"58d7c70a6d6ccfd2dfb19991c33d41f6fa8bcdf923433361e9630a1f89386e72\", \"target_hash\": \"3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0ebfda1a01ec05745d43\", \"exact_match\": 0.0}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./eval_llama31-8B/kmmlu/direct_food_processing/0-shot/meta-llama__Meta-Llama-3.1-8B/samples_kmmlu_direct_food_processing_2024-08-22T10-37-31.530806.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63bfba8b-1adc-44f1-b202-d591c0e6c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd874b1-8e66-42a4-8bc6-bbc3f681a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_kmmlu_direct_food_processing = '''\n",
    "task: kmmlu_direct_food_processing_filtered\n",
    "dataset_path: HAERAE-HUB/KMMLU\n",
    "dataset_name: Food-Processing\n",
    "output_type: generate_until\n",
    "test_split: test\n",
    "fewshot_split: dev\n",
    "doc_to_text: \"{{question.strip()}}\\nA. {{A}}\\nB. {{B}}\\nC. {{C}}\\nD. {{D}}\\n정답：\"\n",
    "doc_to_target: \"{{['A', 'B', 'C', 'D'][answer-1]}}\"\n",
    "metric_list:\n",
    "  - metric: exact_match\n",
    "    aggregation: mean\n",
    "    higher_is_better: true\n",
    "    ignore_case: true\n",
    "    ignore_punctuation: true\n",
    "    regexes_to_ignore:\n",
    "          - \" \"\n",
    "generation_kwargs:\n",
    "  until:\n",
    "    - \"Q:\"\n",
    "    - \"\\n\\n\"\n",
    "    - \"</s>\"\n",
    "    - \".\"\n",
    "  do_sample: false\n",
    "  temperature: 0.0\n",
    "filter_list:\n",
    "  - name: \"get-answer\"\n",
    "    filter:\n",
    "      - function: \"regex\"\n",
    "        regex_pattern: \"[A-D]\"\n",
    "      - function: \"take_first\"\n",
    "metadata:\n",
    "  version: 2.0\n",
    "'''\n",
    "with open('./template/kmmlu_direct_food_processing_filtered.yaml', 'w') as f:\n",
    "    f.write(YAML_kmmlu_direct_food_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f020ca-6bc5-4acd-96ad-6f753dbf1719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22:10:54:15,772 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2024-08-22:10:54:15,772 INFO     [__main__.py:303] Including path: ./template\n",
      "2024-08-22:10:54:15,774 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2024-08-22:10:54:20,777 INFO     [__main__.py:376] Selected Tasks: ['kmmlu_direct_food_processing_filtered']\n",
      "2024-08-22:10:54:20,778 INFO     [evaluator.py:158] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42\n",
      "2024-08-22:10:54:20,778 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B', 'dtype': 'auto'}\n",
      "2024-08-22:10:54:20,813 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
      "2024-08-22:10:54:21,368 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:03<00:00,  1.33it/s]\n",
      "2024-08-22:10:54:25,991 WARNING  [evaluator.py:262] Overwriting default num_fewshot of kmmlu_direct_food_processing_filtered from None to 0\n",
      "2024-08-22:10:54:25,992 INFO     [evaluator.py:274] Setting fewshot random generator seed to 42\n",
      "2024-08-22:10:54:25,992 INFO     [task.py:423] Building contexts for kmmlu_direct_food_processing_filtered on rank 0...\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1495.54it/s]\n",
      "2024-08-22:10:54:26,708 INFO     [evaluator.py:457] Running generate_until requests\n",
      "Running generate_until requests:   0%|                 | 0/1000 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Determined Largest batch size: 1\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Running generate_until requests: 100%|██████| 1000/1000 [02:02<00:00,  8.20it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /home/jovyan)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "{\n",
      "  \"results\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": {\n",
      "      \"alias\": \"kmmlu_direct_food_processing_filtered\",\n",
      "      \"exact_match,get-answer\": 0.309,\n",
      "      \"exact_match_stderr,get-answer\": 0.014619600977206493\n",
      "    }\n",
      "  },\n",
      "  \"group_subtasks\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": []\n",
      "  },\n",
      "  \"configs\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": {\n",
      "      \"task\": \"kmmlu_direct_food_processing_filtered\",\n",
      "      \"dataset_path\": \"HAERAE-HUB/KMMLU\",\n",
      "      \"dataset_name\": \"Food-Processing\",\n",
      "      \"test_split\": \"test\",\n",
      "      \"fewshot_split\": \"dev\",\n",
      "      \"doc_to_text\": \"{{question.strip()}} A. {{A}} B. {{B}} C. {{C}} D. {{D}} 정답：\",\n",
      "      \"doc_to_target\": \"{{['A', 'B', 'C', 'D'][answer-1]}}\",\n",
      "      \"description\": \"\",\n",
      "      \"target_delimiter\": \" \",\n",
      "      \"fewshot_delimiter\": \"\\n\\n\",\n",
      "      \"num_fewshot\": 0,\n",
      "      \"metric_list\": [\n",
      "        {\n",
      "          \"metric\": \"exact_match\",\n",
      "          \"aggregation\": \"mean\",\n",
      "          \"higher_is_better\": true,\n",
      "          \"ignore_case\": true,\n",
      "          \"ignore_punctuation\": true,\n",
      "          \"regexes_to_ignore\": [\n",
      "            \" \"\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"output_type\": \"generate_until\",\n",
      "      \"generation_kwargs\": {\n",
      "        \"until\": [\n",
      "          \"Q:\",\n",
      "          \"\\n\",\n",
      "          \"</s>\",\n",
      "          \".\"\n",
      "        ],\n",
      "        \"do_sample\": false,\n",
      "        \"temperature\": 0.0\n",
      "      },\n",
      "      \"repeats\": 1,\n",
      "      \"filter_list\": [\n",
      "        {\n",
      "          \"name\": \"get-answer\",\n",
      "          \"filter\": [\n",
      "            {\n",
      "              \"function\": \"regex\",\n",
      "              \"regex_pattern\": \"[A-D]\"\n",
      "            },\n",
      "            {\n",
      "              \"function\": \"take_first\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"should_decontaminate\": false,\n",
      "      \"metadata\": {\n",
      "        \"version\": 2.0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"versions\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": 2.0\n",
      "  },\n",
      "  \"n-shot\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": 0\n",
      "  },\n",
      "  \"higher_is_better\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": {\n",
      "      \"exact_match\": true\n",
      "    }\n",
      "  },\n",
      "  \"n-samples\": {\n",
      "    \"kmmlu_direct_food_processing_filtered\": {\n",
      "      \"original\": 1000,\n",
      "      \"effective\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"model\": \"hf\",\n",
      "    \"model_args\": \"pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto\",\n",
      "    \"model_num_parameters\": 8030261248,\n",
      "    \"model_dtype\": \"torch.bfloat16\",\n",
      "    \"model_revision\": \"main\",\n",
      "    \"model_sha\": \"48d6d0fc4e02fb1269b36940650a1b7233035cbb\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"batch_sizes\": [],\n",
      "    \"device\": \"cuda:0\",\n",
      "    \"use_cache\": null,\n",
      "    \"limit\": null,\n",
      "    \"bootstrap_iters\": 100000,\n",
      "    \"gen_kwargs\": null,\n",
      "    \"random_seed\": 42,\n",
      "    \"numpy_seed\": 42,\n",
      "    \"torch_seed\": 42,\n",
      "    \"fewshot_seed\": 42\n",
      "  },\n",
      "  \"git_hash\": null,\n",
      "  \"date\": 1724324060.7775342,\n",
      "  \"pretty_env_info\": \"PyTorch version: 2.3.0+cu121\\nIs debug build: False\\nCUDA used to build PyTorch: 12.1\\nROCM used to build PyTorch: N/A\\n\\nOS: Ubuntu 22.04.3 LTS (x86_64)\\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\\nClang version: Could not collect\\nCMake version: Could not collect\\nLibc version: glibc-2.35\\n\\nPython version: 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0] (64-bit runtime)\\nPython platform: Linux-6.5.0-1024-azure-x86_64-with-glibc2.35\\nIs CUDA available: True\\nCUDA runtime version: Could not collect\\nCUDA_MODULE_LOADING set to: LAZY\\nGPU models and configuration: GPU 0: NVIDIA A100 80GB PCIe\\nNvidia driver version: 535.183.01\\ncuDNN version: Could not collect\\nHIP runtime version: N/A\\nMIOpen runtime version: N/A\\nIs XNNPACK available: True\\n\\nCPU:\\nArchitecture:                       x86_64\\nCPU op-mode(s):                     32-bit, 64-bit\\nAddress sizes:                      48 bits physical, 48 bits virtual\\nByte Order:                         Little Endian\\nCPU(s):                             24\\nOn-line CPU(s) list:                0-23\\nVendor ID:                          AuthenticAMD\\nModel name:                         AMD EPYC 7V13 64-Core Processor\\nCPU family:                         25\\nModel:                              1\\nThread(s) per core:                 1\\nCore(s) per socket:                 24\\nSocket(s):                          1\\nStepping:                           1\\nBogoMIPS:                           4890.88\\nFlags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl tsc_reliable nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext perfctr_core invpcid_single vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves clzero xsaveerptr rdpru arat umip vaes vpclmulqdq rdpid fsrm\\nHypervisor vendor:                  Microsoft\\nVirtualization type:                full\\nL1d cache:                          768 KiB (24 instances)\\nL1i cache:                          768 KiB (24 instances)\\nL2 cache:                           12 MiB (24 instances)\\nL3 cache:                           96 MiB (3 instances)\\nNUMA node(s):                       1\\nNUMA node0 CPU(s):                  0-23\\nVulnerability Gather data sampling: Not affected\\nVulnerability Itlb multihit:        Not affected\\nVulnerability L1tf:                 Not affected\\nVulnerability Mds:                  Not affected\\nVulnerability Meltdown:             Not affected\\nVulnerability Mmio stale data:      Not affected\\nVulnerability Retbleed:             Not affected\\nVulnerability Spec rstack overflow: Vulnerable: Safe RET, no microcode\\nVulnerability Spec store bypass:    Vulnerable\\nVulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\nVulnerability Spectre v2:           Mitigation; Retpolines; STIBP disabled; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected\\nVulnerability Srbds:                Not affected\\nVulnerability Tsx async abort:      Not affected\\n\\nVersions of relevant libraries:\\n[pip3] numpy==1.24.4\\n[pip3] torch==2.3.0+cu121\\n[pip3] torchaudio==2.3.0+cu121\\n[pip3] torchvision==0.18.0+cu121\\n[pip3] triton==2.3.0\\n[conda] nomkl                     1.0                  h5ca1d4c_0    conda-forge\\n[conda] numpy                     1.24.4          py311h64a7726_0    conda-forge\\n[conda] torch                     2.3.0+cu121              pypi_0    pypi\\n[conda] torchaudio                2.3.0+cu121              pypi_0    pypi\\n[conda] torchvision               0.18.0+cu121             pypi_0    pypi\\n[conda] triton                    2.3.0                    pypi_0    pypi\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"upper_git_hash\": null,\n",
      "  \"tokenizer_pad_token\": [\n",
      "    \"<|end_of_text|>\",\n",
      "    \"128001\"\n",
      "  ],\n",
      "  \"tokenizer_eos_token\": [\n",
      "    \"<|end_of_text|>\",\n",
      "    \"128001\"\n",
      "  ],\n",
      "  \"tokenizer_bos_token\": [\n",
      "    \"<|begin_of_text|>\",\n",
      "    \"128000\"\n",
      "  ],\n",
      "  \"eot_token_id\": 128001,\n",
      "  \"max_length\": 131072\n",
      "}\n",
      "2024-08-22:10:56:36,452 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
      "2024-08-22:10:56:36,453 INFO     [evaluation_tracker.py:287] Saving per-sample results for: kmmlu_direct_food_processing_filtered\n",
      "hf (pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: auto\n",
      "|                Tasks                |Version|  Filter  |n-shot|  Metric   |   |Value|   |Stderr|\n",
      "|-------------------------------------|------:|----------|-----:|-----------|---|----:|---|-----:|\n",
      "|kmmlu_direct_food_processing_filtered|      2|get-answer|     0|exact_match|↑  |0.309|±  |0.0146|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=auto \\\n",
    "    --include_path ./template \\\n",
    "    --tasks kmmlu_direct_food_processing_filtered \\\n",
    "    --num_fewshot 0 \\\n",
    "    --seed 42 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto\\\n",
    "    --output_path ./eval_llama31-8B/kmmlu/direct_food_processing/0-shot \\\n",
    "    --log_samples \\\n",
    "    --show_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3201894-c657-4e08-bff1-3a91d04031e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2024-08-22T10-37-31.530806.json\n",
      "results_2024-08-22T10-56-36.453767.json\n",
      "samples_kmmlu_direct_food_processing_2024-08-22T10-37-31.530806.jsonl\n",
      "samples_kmmlu_direct_food_processing_filtered_2024-08-22T10-56-36.453767.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls ./eval_llama31-8B/kmmlu/direct_food_processing/0-shot/meta-llama__Meta-Llama-3.1-8B/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69f1508-7e3a-4b65-b98f-2eb408dd94ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"doc_id\": 0, \"doc\": {\"question\": \"산성암, 중성암, 염기성암의 분류기분이 되는 것은?\", \"answer\": 2, \"A\": \"SiO2\", \"B\": \"Al2O3\", \"C\": \"P2O5\", \"D\": \"Fe2O3\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0435}, \"target\": \"B\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"산성암, 중성암, 염기성암의 분류기분이 되는 것은? A. SiO2 B. Al2O3 C. P2O5 D. Fe2O3 정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"A\"]], \"filtered_resps\": [\"A\"], \"doc_hash\": \"139b202ef728343bfaa798fae16ca033d6ff3cced5c0243ebd7fae6d4e99e0d5\", \"prompt_hash\": \"f38ca08879a428518f5acdabe20340fdb6eaa106e4edd2b3c6da4b19460dd80d\", \"target_hash\": \"df7e70e5021544f4834bbee64a9e3789febc4be81470df629cad6ddb03320a5c\", \"exact_match\": 0.0}\n",
      "{\"doc_id\": 1, \"doc\": {\"question\": \"어류의 생식선 자극 호르몬에 대한 설명 중 바르게 된 것은?\", \"answer\": 3, \"A\": \"뇌하수체의 전엽단부의 대부분을 차지하며, 에리드로신에 잘 염색되는 세포에서 생산, 분비된다.\", \"B\": \"어류의 간신선을 자극하여 코티졸이나 코티존의 생산, 분비를 촉진한다.\", \"C\": \"뇌하수체 전엽주부에서 생산, 분비되고 당단백질을 함유한 과립을 세포질 가운데 많이 가진다.\", \"D\": \"뇌하수체 중엽에서 생산, 분비되는 호르몬이다.\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0588}, \"target\": \"C\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"어류의 생식선 자극 호르몬에 대한 설명 중 바르게 된 것은? A. 뇌하수체의 전엽단부의 대부분을 차지하며, 에리드로신에 잘 염색되는 세포에서 생산, 분비된다. B. 어류의 간신선을 자극하여 코티졸이나 코티존의 생산, 분비를 촉진한다. C. 뇌하수체 전엽주부에서 생산, 분비되고 당단백질을 함유한 과립을 세포질 가운데 많이 가진다. D. 뇌하수체 중엽에서 생산, 분비되는 호르몬이다. 정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"C\"]], \"filtered_resps\": [\"C\"], \"doc_hash\": \"c2a17f8a42822239d828fa1819c221c589aad977123235ba3ddfca0a2803caf4\", \"prompt_hash\": \"d53bf0b632b96a824a8be7318491fe3ed9016c3044c00bed0b186c867726fb08\", \"target_hash\": \"6b23c0d5f35d1b11f9b683f0b0a617355deb11277d91ae091d399c655b87940d\", \"exact_match\": 1.0}\n",
      "{\"doc_id\": 2, \"doc\": {\"question\": \"광합성에서의 ATP 생성은 광인산화(photophosphorylation)에 의해 생성된다. 광인산화에 관한 설명 중 옳은 것은?\", \"answer\": 2, \"A\": \"미토콘드리아내막에서 일어난다.\", \"B\": \"광인산화는 전자전달과 짝지어져 일어난다.\", \"C\": \"미토콘드리아의 산화적 인산화 반응과 다른 분자 메카니즘으로 일어난다.\", \"D\": \"ATP는 비순환적 인산화(noncyclic photophosphorylatio-n photophosphorylation)에 의해서만 생성된다.\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0588}, \"target\": \"B\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"광합성에서의 ATP 생성은 광인산화(photophosphorylation)에 의해 생성된다. 광인산화에 관한 설명 중 옳은 것은? A. 미토콘드리아내막에서 일어난다. B. 광인산화는 전자전달과 짝지어져 일어난다. C. 미토콘드리아의 산화적 인산화 반응과 다른 분자 메카니즘으로 일어난다. D. ATP는 비순환적 인산화(noncyclic photophosphorylatio-n photophosphorylation)에 의해서만 생성된다. 정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"B\"]], \"filtered_resps\": [\"B\"], \"doc_hash\": \"b422673dbae842c1014580b71319b4927aaca0a54627c753eb493958c19f4c06\", \"prompt_hash\": \"3a0fb014c07e54cd51daa932b255539cd71968f751e535fd59b8917f4aecda68\", \"target_hash\": \"df7e70e5021544f4834bbee64a9e3789febc4be81470df629cad6ddb03320a5c\", \"exact_match\": 1.0}\n",
      "{\"doc_id\": 3, \"doc\": {\"question\": \"구상흑연주철에서 페라이트가 석출한 페라이트형 주철의 생성은 어느 경우에 발생되는가?\", \"answer\": 3, \"A\": \"냉각속도가 빠를 때\", \"B\": \"Mn 첨가량이 많을 때\", \"C\": \"C, Si 특히 Si가 많을 때\", \"D\": \"담금질 및 뜨임 하였을 때\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0625}, \"target\": \"C\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"구상흑연주철에서 페라이트가 석출한 페라이트형 주철의 생성은 어느 경우에 발생되는가? A. 냉각속도가 빠를 때 B. Mn 첨가량이 많을 때 C. C, Si 특히 Si가 많을 때 D. 담금질 및 뜨임 하였을 때 정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"C\"]], \"filtered_resps\": [\"C\"], \"doc_hash\": \"9daf78762cfd784a5315f5fec74f416c68a1e82567ed8a49d777fd41ec654118\", \"prompt_hash\": \"42c76546ff87dd810b855316a64f31d1a22a9ffb5536a86287ceddecc326b767\", \"target_hash\": \"6b23c0d5f35d1b11f9b683f0b0a617355deb11277d91ae091d399c655b87940d\", \"exact_match\": 1.0}\n",
      "{\"doc_id\": 4, \"doc\": {\"question\": \"유기산 발효 중 직접산화발효가 아닌 것은?\", \"answer\": 4, \"A\": \"Acetic acid 발효\", \"B\": \"5-ketogluconic acid 발효\", \"C\": \"Gluconic acid 발효\", \"D\": \"Fumaric acid 발효\", \"Category\": \"Food Processing\", \"Human Accuracy\": 0.0625}, \"target\": \"D\", \"arguments\": {\"gen_args_0\": {\"arg_0\": \"유기산 발효 중 직접산화발효가 아닌 것은? A. Acetic acid 발효 B. 5-ketogluconic acid 발효 C. Gluconic acid 발효 D. Fumaric acid 발효 정답：\", \"arg_1\": {\"until\": [\"Q:\", \"\\n\", \"</s>\", \".\"], \"do_sample\": false, \"temperature\": 0.0}}}, \"resps\": [[\"C 2\"]], \"filtered_resps\": [\"C\"], \"doc_hash\": \"e18aaeb7c162ee981120d0aa5929e5020daa617a501d26031b6b20b8a3eb0381\", \"prompt_hash\": \"3700f0193eaf745aa8b0351edefccbeca69943aad64c90f9b2218645c1bb8c82\", \"target_hash\": \"3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0ebfda1a01ec05745d43\", \"exact_match\": 0.0}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./eval_llama31-8B/kmmlu/direct_food_processing/0-shot/meta-llama__Meta-Llama-3.1-8B/samples_kmmlu_direct_food_processing_filtered_2024-08-22T10-56-36.453767.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e57a32-a67d-46ed-a211-ea7447fd2df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
