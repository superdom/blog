{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa0b9a3-f26f-4387-aa68-5a956ab9041e",
   "metadata": {},
   "source": [
    "* 아래 코드는 S1 모델의 학습 코드를 기반으로 재구성하였습니다.\n",
    "* https://github.com/simplescaling/s1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b0d08-17f0-441e-8e44-3ad7295c3412",
   "metadata": {},
   "source": [
    "# 학습 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b46d0-c63b-41e1-a2c7-fe4912cf23f1",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c0ec83-6cbf-416d-a421-3fb966aeca60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: bitsandbytes in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (0.45.2)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: peft in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (0.13.3.dev0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: accelerate in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: datasets in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (3.1.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: trl in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (0.15.1)\n",
      "Collecting trl\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: flash_attn in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (2.7.4.post1)\n",
      "Requirement already satisfied: vllm in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (0.7.2)\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: psutil in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: rich in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: einops in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from flash_attn) (0.8.1)\n",
      "Requirement already satisfied: sentencepiece in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.2.0)\n",
      "Collecting numba==0.60.0 (from vllm)\n",
      "  Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: blake3 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: protobuf in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (3.20.3)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.115.8)\n",
      "Requirement already satisfied: openai>=1.52.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (1.54.3)\n",
      "Requirement already satisfied: pydantic>=2.9 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (2.9.2)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.21.0)\n",
      "Requirement already satisfied: pillow in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (11.1.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (7.0.2)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.10.10)\n",
      "Requirement already satisfied: outlines==0.1.11 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (1.2.2)\n",
      "Collecting xgrammar==0.1.11 (from vllm)\n",
      "  Downloading xgrammar-0.1.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: partial-json-parser in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (25.1.2)\n",
      "Requirement already satisfied: msgspec in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (8.5.0)\n",
      "Requirement already satisfied: mistral_common>=1.5.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (1.5.3)\n",
      "Requirement already satisfied: compressed-tensors==0.9.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.9.1)\n",
      "Requirement already satisfied: depyf==0.18.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (3.1.1)\n",
      "Collecting ray==2.40.0 (from ray[adag]==2.40.0->vllm)\n",
      "  Downloading ray-2.40.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (2.5.1)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.20.1)\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from vllm) (0.0.28.post3)\n",
      "Requirement already satisfied: astor in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba==0.60.0->vllm)\n",
      "  Using cached llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: interegular in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (3.1.4)\n",
      "Requirement already satisfied: nest_asyncio in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (0.35.1)\n",
      "Requirement already satisfied: jsonschema in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "Requirement already satisfied: pycountry in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (20241001)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
      "Requirement already satisfied: click>=7.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (8.1.7)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.5.0)\n",
      "Collecting cupy-cuda12x (from ray[adag]==2.40.0->vllm)\n",
      "  Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: networkx in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: pybind11 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from xgrammar==0.1.11->vllm) (2.13.6)\n",
      "Requirement already satisfied: pytest in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from xgrammar==0.1.11->vllm) (8.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.45.3)\n",
      "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.27.2)\n",
      "Collecting jinja2 (from outlines==0.1.11->vllm)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.34.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pydantic>=2.9->vllm) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: zipp>=3.20 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from importlib_metadata->vllm) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from rich->trl) (2.18.0)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Downloading rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
      "Requirement already satisfied: httpcore==1.* in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from jinja2->outlines==0.1.11->vllm) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm) (15.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[adag]==2.40.0->vllm)\n",
      "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: iniconfig in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pytest->xgrammar==0.1.11->vllm) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages (from pytest->xgrammar==0.1.11->vllm) (1.5.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m101.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl (264.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "Downloading ray-2.40.0-cp311-cp311-manylinux2014_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m205.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m292.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading cupy_cuda12x-13.4.0-cp311-cp311-manylinux2014_x86_64.whl (105.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
      "Downloading rich_toolkit-0.13.2-py3-none-any.whl (13 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: fastrlock, shellingham, python-multipart, llvmlite, jinja2, dnspython, cupy-cuda12x, numba, email-validator, typer, rich-toolkit, ray, fastapi-cli, datasets, bitsandbytes, xgrammar, trl, peft, vllm\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: ray\n",
      "    Found existing installation: ray 2.42.1\n",
      "    Uninstalling ray-2.42.1:\n",
      "      Successfully uninstalled ray-2.42.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.1.0\n",
      "    Uninstalling datasets-3.1.0:\n",
      "      Successfully uninstalled datasets-3.1.0\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.45.2\n",
      "    Uninstalling bitsandbytes-0.45.2:\n",
      "      Successfully uninstalled bitsandbytes-0.45.2\n",
      "  Attempting uninstall: xgrammar\n",
      "    Found existing installation: xgrammar 0.1.13\n",
      "    Uninstalling xgrammar-0.1.13:\n",
      "      Successfully uninstalled xgrammar-0.1.13\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.15.1\n",
      "    Uninstalling trl-0.15.1:\n",
      "      Successfully uninstalled trl-0.15.1\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.13.3.dev0\n",
      "    Uninstalling peft-0.13.3.dev0:\n",
      "      Successfully uninstalled peft-0.13.3.dev0\n",
      "  Attempting uninstall: vllm\n",
      "    Found existing installation: vllm 0.7.2\n",
      "    Uninstalling vllm-0.7.2:\n",
      "      Successfully uninstalled vllm-0.7.2\n",
      "Successfully installed bitsandbytes-0.45.3 cupy-cuda12x-13.4.0 datasets-3.3.2 dnspython-2.7.0 email-validator-2.2.0 fastapi-cli-0.0.7 fastrlock-0.8.3 jinja2-3.1.6 llvmlite-0.43.0 numba-0.60.0 peft-0.14.0 python-multipart-0.0.20 ray-2.40.0 rich-toolkit-0.13.2 shellingham-1.5.4 trl-0.15.2 typer-0.15.2 vllm-0.7.3 xgrammar-0.1.11\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers bitsandbytes peft accelerate datasets trl flash_attn vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3eff5-5ac4-4054-80a4-659a978fedda",
   "metadata": {},
   "source": [
    "## 2. 모듈 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35dfbd2f-7a73-4683-8291-648a75b76340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c815bde-36ff-40a8-a06f-492175bf7cf8",
   "metadata": {},
   "source": [
    "## 3. 모델 및 토크나이저 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e5da54-d65e-433d-82a4-d99ef974b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0563c9245ef4b7da37d90058ff09d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ab6521-a936-4e77-b49c-8d78101a7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "tokenizer.pad_token = \"<|fim_pad|>\"\n",
    "tokenizer.pad_token_id = 151662\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf193b5-2ee8-4bb8-b750-93b186d1be93",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdf9e2de-dd40-42d1-96cb-db525fb333a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"werty1248/s1k-1.1-Ko-ReGenerated-Formatted\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca528dd9-944a-44f4-8ef4-c8d465612152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'question', 'question_ko', 'reasoning_ko', 'answer_ko', 'boxed_ko', 'deepseek_answer', 'deepseek_boxed', 'gemini_naswer', 'gemini_boxed', 'solution', 'text'],\n",
       "    num_rows: 984\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a332658-425c-4225-a3c7-885d06bdd938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QUERY_TEMPLATE_NOANSWER = \"\"\"{Question}\"\"\".strip()\n",
    "\n",
    "def process_cot_example(example: Dict, tokenizer):\n",
    "    thinking_trajectory = example[\"reasoning_ko\"]\n",
    "    question = example[\"question_ko\"]\n",
    "    answer = example[\"answer_ko\"]\n",
    "\n",
    "    prompt = QUERY_TEMPLATE_NOANSWER.format(Question=question)\n",
    "    answer = \"Answer: \" + answer if \"Answer:\" not in answer else answer\n",
    "    text = tokenizer.apply_chat_template([\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"<|im_start|>think\\n\" + thinking_trajectory.strip() + \n",
    "                       \"\\n<|im_start|>answer\\n\" + answer.strip()\n",
    "        }\n",
    "    ], tokenize=False)\n",
    "    return dict(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1531f5-59fe-4f5a-883f-939eb4445039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda example: process_cot_example(example, tokenizer))\n",
    "dataset = dataset.remove_columns([col for col in dataset.column_names if col != \"text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3710b64f-4fcc-4d11-812f-b9c1200632e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 984\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839083dd-112a-487d-a912-a14af41499c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "유리수를 주면, 이를 기약 분수 형태로 나타내고, 그 결과 분자와 분모의 곱을 계산하세요. 0과 1 사이의 유리수 중에서 얼마의 유리수에 대해 그 결과 곱이 $20_{}^{}!$이 되겠습니까?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|im_start|>think\n",
      "좋아, 이 문제를 풀어봐야겠다. 문제는 0과 1 사이의 유리수를 기약 분수 형태로 나타내고, 그 분자와 분모의 곱이 20!이 되는 경우의 수를 구하는 거야. \n",
      "\n",
      "먼저, 유리수는 a/b 형태로 나타낼 수 있고, 0과 1 사이이니까 a < b이고, a와 b는 서로소여야 기약 분수겠지. 그리고 분자와 분모의 곱이 20!이 되어야 하니까 a * b = 20! 이라는 조건이 생기는 거야. \n",
      "\n",
      "그러면 문제는 결국 a와 b가 서로소이고, a < b, a*b = 20!을 만족하는 (a, b) 쌍의 개수를 찾는 거네. \n",
      "\n",
      "여기서 a와 b가 서로소이면서 곱이 20!이 되려면, a와 b는 20!의 약수 중에서 서로소인 두 수의 쌍이어야 해. 그리고 a < b라는 조건도 있으니까. \n",
      "\n",
      "그런데 a와 b가 서로소이고 a*b = N (여기서 N은 20!이야)이라면, a와 b는 N의 약수 중에서 서로소인 쌍이어야 해. 이때, a와 b는 서로소이기 때문에 N의 소인수분해에서 각 소인수들은 a나 b 중 하나에만 포함되어야 해. \n",
      "\n",
      "예를 들어, N = p1^e1 * p2^e2 * ... * pn^en 이라면, 각 소인수 pi는 a 또는 b 중 하나에만 속해야 해. 그래서 각 소인수마다 a에 할당할지 b에 할당할지 2가지 선택지가 생기고, 따라서 총 2^k 가지의 경우의 수가 나오겠지. 여기서 k는 N의 서로 다른 소인수의 개수야. \n",
      "\n",
      "하지만 문제에서는 a < b인 경우만 세야 하니까, 모든 경우의 수에서 대칭인 쌍 (a,b)와 (b,a) 중 하나만 세야 해. 단, a ≠ b인 경우에만 그렇고, a = b인 경우는 없을 거야. 왜냐하면 a와 b가 서로소이려면 a = b =1 이어야 하는데, a*b=20!이면 1*1=1 ≠ 20!이므로 a ≠ b가 확실해. \n",
      "\n",
      "따라서 전체 경우의 수는 2^k 이고, a < b인 경우는 절반이니까 2^{k-1} 이 되겠네. \n",
      "\n",
      "이제 20!의 소인수분해를 해야 해. 20!의 소인수는 20 이하의 모든 소수들일 거야. 20 이하의 소수는 2, 3, 5, 7, 11, 13, 17, 19. 총 8개야. \n",
      "\n",
      "그러니까 k=8이므로 2^8 = 256개의 순서쌍 (a,b)가 있고, a < b인 경우는 256 / 2 = 128개가 되겠네. \n",
      "\n",
      "그래서 정답은 128? \n",
      "\n",
      "잠깐, 이게 맞나? 예를 들어 N이 제곱수인 경우에는 a와 b가 같은 경우가 있을 수 있지만, 이 문제에서는 a와 b가 서로소이고 a*b=20!이므로 a와 b가 같을 수는 없어. 왜냐하면 a = b라면 a^2 = 20!이 되고, a는 20!의 제곱근이어야 하는데, 20!은 완전제곱수가 아니기 때문이야. 따라서 모든 쌍은 a ≠ b이고, 대칭쌍이므로 절반으로 나누는 게 맞아. \n",
      "\n",
      "그래서 2^8 / 2 = 128이 맞는 것 같아. \n",
      "\n",
      "그럼 최종 답은 128?\n",
      "<|im_start|>answer\n",
      "Answer: 0과 1 사이의 유리수를 기약 분수 $\\frac{a}{b}$로 나타낼 때, $a$와 $b$는 서로소이며 $a < b$이고 $a \\cdot b = 20!$을 만족해야 합니다. $20!$의 소인수는 20 이하의 소수인 2, 3, 5, 7, 11, 13, 17, 19로 총 8개입니다. 각 소인수는 $a$ 또는 $b$ 중 하나에만 포함되어야 하므로, 경우의 수는 $2^8 = 256$입니다. 이 중 $a < b$인 경우는 대칭쌍의 절반이므로 $256 / 2 = 128$입니다.\n",
      "\n",
      "$\\boxed{128}$<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6177ada-a301-458c-bdc5-27c8d5c1aad7",
   "metadata": {},
   "source": [
    "## 5. 토큰 길이 분석 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbe0214-e25c-4c8a-8d14-f9af28e0ffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 토큰 수: 40812\n",
      "최소 토큰 수: 825\n"
     ]
    }
   ],
   "source": [
    "token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in dataset['text']]\n",
    "\n",
    "max_tokens = max(token_lengths)\n",
    "min_tokens = min(token_lengths)\n",
    "max_text = dataset['text'][token_lengths.index(max_tokens)]\n",
    "min_text = dataset['text'][token_lengths.index(min_tokens)]\n",
    "\n",
    "print(f\"최대 토큰 수: {max_tokens}\")\n",
    "print(f\"최소 토큰 수: {min_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0a0997-2363-45ac-9900-d04a9acbb086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49368 (\\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54540 (\\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54596 (\\N{HANGUL SYLLABLE PIL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51032 (\\N{HANGUL SYLLABLE YI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 53664 (\\N{HANGUL SYLLABLE TO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 53360 (\\N{HANGUL SYLLABLE KEUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/giant-data/user/1111332/.conda/envs/jupyter/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(token_lengths, bins=30, edgecolor='black')\n",
    "plt.xlabel(\"토큰 개수\")\n",
    "plt.ylabel(\"샘플 수\")\n",
    "plt.title(\"Text 필드의 토큰 분포\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08b3c6-1dfb-4b02-87ca-9e56b9f5a3bc",
   "metadata": {},
   "source": [
    "## 6. LoRA 구성 및 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5325f68a-5894-4166-ba3d-7be41cb22606",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=32,            \n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules= ['k_proj', 'o_proj','q_proj', 'v_proj', 'up_proj', 'down_proj', 'gate_proj'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9c5e47f-b65e-49e2-959f-6abc76324143",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = SFTConfig(\n",
    "    output_dir=\"./output\",\n",
    "    optim=\"adamw_8bit\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=32,\n",
    "    gradient_checkpointing=True,\n",
    "    log_level=\"debug\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=2,\n",
    "    learning_rate=5e-5,\n",
    "    bf16 = True,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=20000,\n",
    "    report_to='none'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1147e5d5-9d5b-4a59-a8f7-4409019ae581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c860f3c977c45d4815ab7b10863c824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6f04ec212445d18c940e71ed503e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using auto half precision backend\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=lora_config,\n",
    "    args=training_arguments,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df265ab8-cfb8-4a61-942b-91fe4215d352",
   "metadata": {},
   "source": [
    "## 7. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f444dda-45e3-4613-834d-f94e54ae0af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 1\n",
      "The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: text. If text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 984\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 32\n",
      "  Total optimization steps = 180\n",
      "  Number of trainable parameters = 80,740,352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 20/180 26:45 < 3:57:54, 0.01 it/s, Epoch 0.62/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.687600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/transformers/trainer.py:3740\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3738\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3740\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/accelerate/accelerator.py:2329\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2329\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64631347-432a-408d-ad20-21833120bf7e",
   "metadata": {},
   "source": [
    "# 추론 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786830fb-ca30-4577-a660-eb76c7767910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e2c0c-303e-46de-8c15-355c010b06c3",
   "metadata": {},
   "source": [
    "## Qwen2.5-7B-Instuct 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d36d377-6ac1-474b-81a8-3da943cf83e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-09 15:56:34 __init__.py:207] Automatically detected platform cuda.\n",
      "INFO 03-09 15:56:44 config.py:549] This model supports multiple tasks: {'reward', 'embed', 'score', 'classify', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 03-09 15:56:44 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='Qwen/Qwen2.5-7B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 03-09 15:56:46 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 03-09 15:56:47 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-7B-Instruct...\n",
      "INFO 03-09 15:56:48 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a8ea5ad38a4f2c8e1203f738997d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-09 15:56:51 model_runner.py:1115] Loading model weights took 14.2487 GB\n",
      "INFO 03-09 15:56:54 worker.py:267] Memory profiling takes 2.40 seconds\n",
      "INFO 03-09 15:56:54 worker.py:267] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.90) = 71.24GiB\n",
      "INFO 03-09 15:56:54 worker.py:267] model weights take 14.25GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 4.35GiB; the rest of the memory reserved for KV Cache is 52.54GiB.\n",
      "INFO 03-09 15:56:54 executor_base.py:111] # cuda blocks: 61490, # CPU blocks: 4681\n",
      "INFO 03-09 15:56:54 executor_base.py:116] Maximum concurrency for 32768 tokens per request: 30.02x\n",
      "INFO 03-09 15:56:57 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:15<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-09 15:57:12 model_runner.py:1562] Graph capturing finished in 15 secs, took 0.78 GiB\n",
      "INFO 03-09 15:57:12 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 20.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LLM(\"Qwen/Qwen2.5-7B-Instruct\", tensor_parallel_size=1,)\n",
    "tok = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c9815c-ec68-4b09-bd06-abc2b1acd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    max_tokens=32768,\n",
    "    min_tokens=0,\n",
    "    skip_special_tokens=False,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573624d8-2304-4642-9c24-4b8a6f4eafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<|im_start|>system\n",
    "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "다음 나열된 숫자들에서 B에 들어갈 숫자는? 61 52 63 94 46 B 차근 차근 단계별로 생각해봐<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036652f4-2b43-4985-90dd-43198bcfdbfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.71s/it, est. speed input: 10.89 toks/s, output: 89.34 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "다음 나열된 숫자들에서 B에 들어갈 숫자는? 61 52 63 94 46 B 차근 차근 단계별로 생각해봐<|im_end|>\n",
      "<|im_start|>assistant\n",
      "이 문제를 해결하기 위해 차근차근 단계별로 생각해볼 수 있습니다. 주어진 숫자열은 61, 52, 63, 94, 46, B입니다. 이 숫자열에서 B에 들어갈 숫자를 찾기 위해 다음과 같은 단계를 따르겠습니다.\n",
      "\n",
      "1. **차이 계산**: 먼저 주어진 숫자들 사이의 차이를 계산해봅시다.\n",
      "   - 61에서 52는 9\n",
      "   - 52에서 63은 11\n",
      "   - 63에서 94는 31\n",
      "   - 94에서 46은 -48\n",
      "\n",
      "2. **차이의 패턴 찾기**: 계산한 차이들을 살펴보면, 9, 11, 31, -48입니다. 이 차이들 사이에는 명확한 패턴이 보이지 않지만, 그 차이들의 변화를 살펴보면, 2, 20, -79라는 패턴이 보입니다. 이는 각 차이가 직전 차이에 대해 큰 변화를 보이고 있습니다.\n",
      "\n",
      "3. **추측과 검증**: 주어진 패턴을 기반으로, 다음 차이를 예측해봅시다. 예를 들어, -48에서 다음 차이를 계산해보면, -48에서 2, 20, -79를 고려하여 다음 차이는 -48 + 2 = -46, -46 + 20 = -26, -26 - 79 = -105 등이 될 수 있습니다. 하지만 이는 복잡해지므로, 단순한 패턴을 찾아보겠습니다.\n",
      "\n",
      "4. **단순 패턴 찾기**: 주어진 숫자열에서 가장 간단한 패턴을 찾아보면, 61에서 52는 9, 52에서 63은 11, 63에서 94는 31, 94에서 46은 -48입니다. 이 중에서 가장 간단한 패턴은 61에서 52는 -9, 52에서 63은 +11, 63에서 94는 +31, 94에서 46은 -48입니다. 이 패턴을 이어가면, 46에서 B는 +20이 될 수 있습니다.\n",
      "\n",
      "따라서, B에 들어갈 숫자는 46 + 20 = 66입니다.\n",
      "\n",
      "결론적으로, B에 들어갈 숫자는 **66**입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "o = model.generate(\n",
    "    prompt,\n",
    "    sampling_params=sampling_params,\n",
    ")\n",
    "print(prompt + o[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84aea775-d042-463d-b323-7a19f10c1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memories\n",
    "del model\n",
    "del tok\n",
    "del o\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8823855-e4cd-4123-b77f-cf77107933d6",
   "metadata": {},
   "source": [
    "## Qwen2.5-7B SFT on S1k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df830812-61a1-4f1f-b3a0-177c38cc8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS_THINKING = 20000\n",
    "NUM_IGNORE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e477828d-084d-4cbc-b180-c4742935def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-09 15:57:45 config.py:549] This model supports multiple tasks: {'reward', 'embed', 'score', 'classify', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 03-09 15:57:45 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='./output/full/checkpoint-366', speculative_config=None, tokenizer='./output/full/checkpoint-366', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=./output/full/checkpoint-366, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 03-09 15:57:45 model_runner.py:1110] Starting to load model ./output/full/checkpoint-366...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa56ef63d7964336ab2ff878603b8ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-09 15:57:49 model_runner.py:1115] Loading model weights took 14.2409 GB\n",
      "INFO 03-09 15:57:51 worker.py:267] Memory profiling takes 1.95 seconds\n",
      "INFO 03-09 15:57:51 worker.py:267] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.90) = 71.24GiB\n",
      "INFO 03-09 15:57:51 worker.py:267] model weights take 14.24GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 4.34GiB; the rest of the memory reserved for KV Cache is 52.65GiB.\n",
      "INFO 03-09 15:57:51 executor_base.py:111] # cuda blocks: 61616, # CPU blocks: 4681\n",
      "INFO 03-09 15:57:51 executor_base.py:116] Maximum concurrency for 32768 tokens per request: 30.09x\n",
      "INFO 03-09 15:57:52 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:14<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-09 15:58:06 model_runner.py:1562] Graph capturing finished in 15 secs, took 0.07 GiB\n",
      "INFO 03-09 15:58:07 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 17.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Full finetuned Model\n",
    "\n",
    "model = LLM(\"./output/full/checkpoint-366\", tensor_parallel_size=1,)\n",
    "tok = AutoTokenizer.from_pretrained(\"./output/full/checkpoint-366\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601134e-524a-4752-bd5e-4e0912e238d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LoRA finetuned Model\n",
    "\n",
    "#LORA_ADAPTER_PATH = \"./output/lora/checkpoint-180\"\n",
    "#model = LLM(\n",
    "#    \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "#    enable_lora=True,\n",
    "#    max_lora_rank=16,\n",
    "#    tensor_parallel_size=1,\n",
    "#)\n",
    "\n",
    "#s1_adapter = LoRARequest(\"s1\", 1, adapter_path)\n",
    "#tok = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c60b36-dcb0-4b76-a659-27232055bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"다음 나열된 숫자들에서 B에 들어갈 숫자는? 61 52 63 94 46 B\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be99953c-679b-4731-a20b-f2959333747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.79s/it, est. speed input: 2.58 toks/s, output: 89.18 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "다음 나열된 숫자들에서 B에 들어갈 숫자는? 61 52 63 94 46 B<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|im_start|>think\n",
      "오, 이 문제는 숫자 패턴을 찾아서 B에 맞는 숫자를 찾는 거네. 일단 주어진 숫자들을 하나씩 살펴봐야겠어. 61, 52, 63, 94, 46, B... \n",
      "\n",
      "일단 각 숫자들을 자세히 보면, 아마도 어떤 규칙이 반복되는 것 같아. 예를 들어, 각 숫자가 이전 숫자와 어떤 관계가 있는지, 혹은 위치에 따라 특정한 변화가 있는지 확인해야 할 것 같아.\n",
      "\n",
      "먼저, 숫자들의 차이를 계산해보는 건 어떨까? 예를 들어, 52에서 61이 되었고, 그 다음 63, 94, 46, B... 이렇게 되면 각각의 차이를 계산해보면 규칙이 있을 수 있겠지.\n",
      "\n",
      "하지만 52에서 61은 9 증가, 63은 11 증가, 94는 31 증가, 46은 48 감소... 이렇게 보면 패턴이 잘 안 보이네. 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 숫자를 이진수로 변환해서 보는 건 어떨까? 어떤 숫자 시퀀스에서 이진수 패턴을 찾는 경우가 있으니까. 예를 들어, 각 숫자의 이진수 표현에서 1의 개수가 홀수인지 짝수인지가 규칙이 될 수 있겠지. 하지만 이 경우 각 숫자를 이진수로 바꿔서 1의 개수를 세어보자.\n",
      "\n",
      "61은 이진수로 111101. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "52는 110100. 1의 개수는 2개. 2는 짝수.\n",
      "\n",
      "63은 111111. 1의 개수는 6개. 6은 짝수.\n",
      "\n",
      "94는 1011110. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "46은 1011110. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "그럼 B 다음의 숫자는 1의 개수가 짝수여야 하나? 그런데 현재 주어진 숫자들 중 마지막이 46인데, 46의 1의 개수는 5개(1011110)로 홀수야. 그럼 다음 숫자는 1의 개수가 홀수여야 하는데, B가 그 다음이니까 B의 1의 개수는 홀수여야 하고, 그 다음 숫자는 짝수여야 하는 식이겠지. 그런데 이게 맞는지 모르겠다. 왜냐하면 이 패턴이 연속된 것인지 확인이 필요해.\n",
      "\n",
      "하지만 이 방법으로는 B를 찾기 어려울 수도 있으니 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 숫자를 9로 나눈 나머지가 어떤 패턴을 이루는지 보는 건 어떨까? 예를 들어, 61 ÷9는 6*9=54, 나머지 7. 52는 5*9=45, 나머지 7. 63은 63으로 나머지 0. 94는 9*10=90, 나머지 4. 46은 4*9=36, 나머지 8. 그럼 B는 9로 나눈 나머지가 어떤 특정한 패턴을 가져야 할까? 예를 들어, 7,7,0,4,8, ... 이런 나머지들이 어떤 규칙이 있는지 보면, 7,7,0,4,8... 이걸 보면 7,7은 2번 반복되고, 0,4,8이 오는 것 같아. 그런데 이 패턴이 2개씩 반복되는 것 같진 않고, 5개의 숫자가 주어졌으니 6번째 숫자의 나머지가 무엇인지 예측해야 해. \n",
      "\n",
      "하지만 이 방법도 확실하지 않아. 다른 방법을 찾아야 할 것 같다.\n",
      "\n",
      "또 다른 가능성은 각 숫자를 7로 나눈 나머지일 수도 있겠다. 61 ÷7은 8*7=56, 나머지 5. 52는 7*7=49, 나머지 3. 63은 9*7=63, 나머지 0. 94는 13*7=91, 나머지 3. 46은 6*7=42, 나머지 4. 그럼 B는 7로 나눈 나머지가 어떤 패턴을 이루는지 보는 거야. 나머지들은 5,3,0,3,4, ?... 이걸 보면 3이 두 번 나오고, 0,3,4가 오는 것 같아. 하지만 이 패턴이 명확하지 않아. 예를 들어, 3,0,3,4, ... 다음이 무엇인지 알 수 없어.\n",
      "\n",
      "아니면 각 숫자를 5로 나눈 나머지? 61은 1, 52는 2, 63은 3, 94는 4, 46은 1. B는 5로 나눈 나머지가 1,2,3,4,1,... 이런 식이라면 아무런 규칙이 없어 보여. 이 방법도 별로인 것 같다.\n",
      "\n",
      "다른 접근 방법이 필요해. 아마도 각 숫자 사이의 차이가 특정한 수열을 이루는 것일 수도 있어. 예를 들어, 61에서 52는 -9, 52에서 63은 +11, 63에서 94는 +31, 94에서 46은 -48. 이 차이들의 수열은 -9, +11, +31, -48. 이 차이들의 패턴을 찾아보자.\n",
      "\n",
      "차이들의 수열: -9, 11, 31, -48. 이 수열의 규칙을 찾아야 해. 예를 들어, 각 차이가 이전 차이에 어떤 연산을 적용한 것일 수 있겠지.\n",
      "\n",
      "-9에서 11로 갈 때, +20. 11에서 31로 갈 때, +20. 31에서 -48로 갈 때, -79. 이 규칙이 일정하지 않아서 복잡해. 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 차이가 이전 두 차이의 합이나 다른 연산을 통해 나오는지? 예를 들어, 첫 번째 차이(-9)와 두 번째 차이(+11)의 합은 +2. 그 다음 차이(+31)는 -9 + 11 + 31 = 31? 아니면 다른 방식? 이 방법도 잘 모르겠다.\n",
      "\n",
      "다른 아이디어: 각 숫자를 10의 자리와 개별적으로 보면? 예를 들어, 61은 6과 1, 52는 5와 2 등. 하지만 이 방법으로는 별다른 패턴이 보이지 않을 것 같아.\n",
      "\n",
      "아니면 각 숫자를 뒤집어서 보면? 예를 들어, 61을 뒤집으면 16, 52는 25, 63은 36, 94는 49, 46은 64. 그런데 이 숫자들이 어떤 규칙이 있는지 보면, 16,25,36,49,64... 이건 모두 완전제곱수네! 4^2,5^2,6^2,7^2,8^2. 그렇다면 B 다음의 숫자도 뒤집으면 완전제곱수가 되어야 하는데, B가 주어진 숫자의 다음이니까, B의 뒤집힌 숫자는 9^2=81이 되어야 할 것 같아. 그렇다면 B는 18이 되어야 해. 왜냐하면 18을 뒤집으면 81이고, 81은 9의 제곱이니까. \n",
      "\n",
      "이 가정을 검증해보자. 주어진 숫자들 61,52,63,94,46, B. 각각을 뒤집으면 16,25,36,49,64, B' (B의 뒤집힌 숫자). 이 숫자들이 4,5,6,7,8,9의 제곱이라면 B'은 9가 되어야 해. 따라서 B는 18이 된다.\n",
      "\n",
      "이게 맞는지 확인해보자. 61 → 16 → 4^2, 52 → 25 →5^2, 63 →36 →6^2, 94 →49 →7^2, 46 →64 →8^2. 그러면 B'이 81 →9^2. 따라서 B는 18이 된다. \n",
      "\n",
      "그렇다면 B=18이 맞는 것 같다. 이 방법이 가장 합리적인 추론인 것 같아. 다른 가능성은 없을까? 예를 들어, 뒤집은 숫자가 제곱수가 되는 것 외에 다른 규칙이 있을 수 있지만, 이 방법이 가장 명확해 보여. \n",
      "\n",
      "그래서 최종 답은 18이 될 것 같다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n\"\n",
    "prompt += \"<|im_start|>user\\n\" + prompts[0] + \"<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "stop_token_ids = tok(\"<|im_start|><|im_end|>\")[\"input_ids\"]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=MAX_TOKENS_THINKING,\n",
    "    min_tokens=0,\n",
    "    stop_token_ids=stop_token_ids,\n",
    "    skip_special_tokens=False,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt += \"<|im_start|>think\"\n",
    "\n",
    "o = model.generate(\n",
    "    prompt,\n",
    "    sampling_params=sampling_params,\n",
    "#    lora_request=s1_adapter\n",
    ")\n",
    "\n",
    "print(prompt + o[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3865e9-b122-46d1-b9b2-3034743ce80f",
   "metadata": {},
   "source": [
    "## With budget forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e674e4c-49ce-4fdc-a4b9-a717c50f8d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it, est. speed input: 1458.53 toks/s, output: 80.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it, est. speed input: 1011.28 toks/s, output: 83.29 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "다음 나열된 숫자들에서 B에 들어갈 숫자는? 61 52 63 94 46 B<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|im_start|>think\n",
      "오, 이 문제는 숫자 패턴을 찾아서 B에 맞는 숫자를 찾는 거네. 일단 주어진 숫자들을 하나씩 살펴봐야겠어. 61, 52, 63, 94, 46, B... \n",
      "\n",
      "일단 각 숫자들을 자세히 보면, 아마도 어떤 규칙이 반복되는 것 같아. 예를 들어, 각 숫자가 이전 숫자와 어떤 관계가 있는지, 혹은 위치에 따라 특정한 변화가 있는지 확인해야 할 것 같아.\n",
      "\n",
      "먼저, 숫자들의 차이를 계산해보는 건 어떨까? 예를 들어, 52에서 61이 되었고, 그 다음 63, 94, 46, B... 이렇게 되면 각각의 차이를 계산해보면 규칙이 있을 수 있겠지.\n",
      "\n",
      "하지만 52에서 61은 9 증가, 63은 11 증가, 94는 31 증가, 46은 48 감소... 이렇게 보면 패턴이 잘 안 보이네. 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 숫자를 이진수로 변환해서 보는 건 어떨까? 어떤 숫자 시퀀스에서 이진수 패턴을 찾는 경우가 있으니까. 예를 들어, 각 숫자의 이진수 표현에서 1의 개수가 홀수인지 짝수인지가 규칙이 될 수 있겠지. 하지만 이 경우 각 숫자를 이진수로 바꿔서 1의 개수를 세어보자.\n",
      "\n",
      "61은 이진수로 111101. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "52는 110100. 1의 개수는 2개. 2는 짝수.\n",
      "\n",
      "63은 111111. 1의 개수는 6개. 6은 짝수.\n",
      "\n",
      "94는 1011110. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "46은 1011110. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "그럼 B 다음의 숫자는 1의 개수가 짝수여야 하나? 그런데 현재 주어진 숫자들 중 마지막이 46인데, 46의 1의 개수는 5개(1011110)로 홀수야. 그럼 다음 숫자는 1의 개수가 홀수여야 하는데, B가 그 다음이니까 B의 1의 개수는 홀수여야 하고, 그 다음 숫자는 짝수여야 하는 식이겠지. 그런데 이게 맞는지 모르겠다. 왜냐하면 이 패턴이 연속된 것인지 확인이 필요해.\n",
      "\n",
      "하지만 이 방법으로는 B를 찾기 어려울 수도 있으니 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 숫자를 9로 나눈 나머지가 어떤 패턴을 이루는지 보는 건 어떨까? 예를 들어, 61 ÷9는 6*9=54, 나머지 7. 52는 5*9=45, 나머지 7. 63은 63으로 나머지 0. 94는 9*10=90, 나머지 4. 46은 4*9=36, 나머지 8. 그럼 B는 9로 나눈 나머지가 어떤 특정한 패턴을 가져야 할까? 예를 들어, 7,7,0,4,8, ... 이런 나머지들이 어떤 규칙이 있는지 보면, 7,7,0,4,8... 이걸 보면 7,7은 2번 반복되고, 0,4,8이 오는 것 같아. 그런데 이 패턴이 2개씩 반복되는 것 같진 않고, 5개의 숫자가 주어졌으니 6번째 숫자의 나머지가 무엇인지 예측해야 해. \n",
      "\n",
      "하지만 이 방법도 확실하지 않아. 다른 방법을 찾아야 할 것 같다.\n",
      "\n",
      "또 다른 가능성은 각 숫자를 7로 나눈 나머지일 수도 있겠다. 61 ÷7은 8*7=56, 나머지 5. 52는 7*7=49, 나머지 3. 63은 9*7=63, 나머지 0. 94는 13*7=91, 나머지 3. 46은 6*7=42, 나머지 4. 그럼 B는 7로 나눈 나머지가 어떤 패턴을 이루는지 보는 거야. 나머지들은 5,3,0,3,4, ?... 이걸 보면 3이 두 번 나오고, 0,3,4가 오는 것 같아. 하지만 이 패턴이 명확하지 않아. 예를 들어, 3,0,3,4, ... 다음이 무엇인지 알 수 없어.\n",
      "\n",
      "아니면 각 숫자를 5로 나눈 나머지? 61은 1, 52는 2, 63은 3, 94는 4, 46은 1. B는 5로 나눈 나머지가 1,2,3,4,1,... 이런 식이라면 아무런 규칙이 없어 보여. 이 방법도 별로인 것 같다.\n",
      "\n",
      "다른 접근 방법이 필요해. 아마도 각 숫자 사이의 차이가 특정한 수열을 이루는 것일 수도 있어. 예를 들어, 61에서 52는 -9, 52에서 63은 +11, 63에서 94는 +31, 94에서 46은 -48. 이 차이들의 수열은 -9, +11, +31, -48. 이 차이들의 패턴을 찾아보자.\n",
      "\n",
      "차이들의 수열: -9, 11, 31, -48. 이 수열의 규칙을 찾아야 해. 예를 들어, 각 차이가 이전 차이에 어떤 연산을 적용한 것일 수 있겠지.\n",
      "\n",
      "-9에서 11로 갈 때, +20. 11에서 31로 갈 때, +20. 31에서 -48로 갈 때, -79. 이 규칙이 일정하지 않아서 복잡해. 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 차이가 이전 두 차이의 합이나 다른 연산을 통해 나오는지? 예를 들어, 첫 번째 차이(-9)와 두 번째 차이(+11)의 합은 +2. 그 다음 차이(+31)는 -9 + 11 + 31 = 31? 아니면 다른 방식? 이 방법도 잘 모르겠다.\n",
      "\n",
      "다른 아이디어: 각 숫자를 10의 자리와 개별적으로 보면? 예를 들어, 61은 6과 1, 52는 5와 2 등. 하지만 이 방법으로는 별다른 패턴이 보이지 않을 것 같아.\n",
      "\n",
      "아니면 각 숫자를 뒤집어서 보면? 예를 들어, 61을 뒤집으면 16, 52는 25, 63은 36, 94는 49, 46은 64. 그런데 이 숫자들이 어떤 규칙이 있는지 보면, 16,25,36,49,64... 이건 모두 완전제곱수네! 4^2,5^2,6^2,7^2,8^2. 그렇다면 B 다음의 숫자도 뒤집으면 완전제곱수가 되어야 하는데, B가 주어진 숫자의 다음이니까, B의 뒤집힌 숫자는 9^2=81이 되어야 할 것 같아. 그렇다면 B는 18이 되어야 해. 왜냐하면 18을 뒤집으면 81이고, 81은 9의 제곱이니까. \n",
      "\n",
      "이 가정을 검증해보자. 주어진 숫자들 61,52,63,94,46, B. 각각을 뒤집으면 16,25,36,49,64, B' (B의 뒤집힌 숫자). 이 숫자들이 4,5,6,7,8,9의 제곱이라면 B'은 9가 되어야 해. 따라서 B는 18이 된다.\n",
      "\n",
      "이게 맞는지 확인해보자. 61 → 16 → 4^2, 52 → 25 →5^2, 63 →36 →6^2, 94 →49 →7^2, 46 →64 →8^2. 그러면 B'이 81 →9^2. 따라서 B는 18이 된다. \n",
      "\n",
      "그렇다면 B=18이 맞는 것 같다. 이 방법이 가장 합리적인 추론인 것 같아. 다른 가능성은 없을까? 예를 들어, 뒤집은 숫자가 제곱수가 되는 것 외에 다른 규칙이 있을 수 있지만, 이 방법이 가장 명확해 보여. \n",
      "\n",
      "그래서 최종 답은 18이 될 것 같다.\n",
      "잠깐, 다시 확인해보자. 각 숫자를 뒤집었을 때 4,5,6,7,8,9의 제곱이 되어야 한다. 61 → 16 (4²), 52 →25 (5²), 63 →36 (6²), 94 →49 (7²), 46 →64 (8²). 그러면 B'은 81 (9²)이 되어야 하므로 B는 18이 된다. 맞는 것 같다. 그럼 답은 18.\n",
      "잠깐, 46을 뒤집으면 64가 되는데, 64는 8²이 맞아. 그러면 B'은 81이 되어야 하므로 B는 18. 이게 맞는 것 같다. 그러면 B=18.\n",
      "Answer: 주어진 숫자열 61, 52, 63, 94, 46, B에서 각 숫자를 뒤집으면 16, 25, 36, 49, 64, B'이 됩니다. 이는 각각 4², 5², 6², 7², 8²에 해당하며, 다음 숫자의 뒤집edList B'은 9²인 81이 됩니다. 따라서 B는 81을 뒤집은 18이 됩니다.\n",
      "\n",
      "$\\boxed{18}$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_str = \"잠깐,\"\n",
    "max_tokens_thinking_tmp = MAX_TOKENS_THINKING\n",
    "\n",
    "for i in range(NUM_IGNORE):\n",
    "    max_tokens_thinking_tmp -= len(o[0].outputs[0].token_ids)\n",
    "    prompt += o[0].outputs[0].text + ignore_str\n",
    "\n",
    "    sampling_params = SamplingParams(\n",
    "        max_tokens=max_tokens_thinking_tmp,\n",
    "        min_tokens=0,\n",
    "        stop_token_ids=stop_token_ids,\n",
    "        skip_special_tokens=False,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    o = model.generate(\n",
    "        prompt,\n",
    "        sampling_params=sampling_params\n",
    "    )\n",
    "\n",
    "print(prompt + o[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7413c73-8d81-49e7-b202-e46f092d811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, est. speed input: 13245.83 toks/s, output: 5.09 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "다음 나열된 숫자들에서 B에 들어갈 숫자는? 61 52 63 94 46 B<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|im_start|>think\n",
      "오, 이 문제는 숫자 패턴을 찾아서 B에 맞는 숫자를 찾는 거네. 일단 주어진 숫자들을 하나씩 살펴봐야겠어. 61, 52, 63, 94, 46, B... \n",
      "\n",
      "일단 각 숫자들을 자세히 보면, 아마도 어떤 규칙이 반복되는 것 같아. 예를 들어, 각 숫자가 이전 숫자와 어떤 관계가 있는지, 혹은 위치에 따라 특정한 변화가 있는지 확인해야 할 것 같아.\n",
      "\n",
      "먼저, 숫자들의 차이를 계산해보는 건 어떨까? 예를 들어, 52에서 61이 되었고, 그 다음 63, 94, 46, B... 이렇게 되면 각각의 차이를 계산해보면 규칙이 있을 수 있겠지.\n",
      "\n",
      "하지만 52에서 61은 9 증가, 63은 11 증가, 94는 31 증가, 46은 48 감소... 이렇게 보면 패턴이 잘 안 보이네. 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 숫자를 이진수로 변환해서 보는 건 어떨까? 어떤 숫자 시퀀스에서 이진수 패턴을 찾는 경우가 있으니까. 예를 들어, 각 숫자의 이진수 표현에서 1의 개수가 홀수인지 짝수인지가 규칙이 될 수 있겠지. 하지만 이 경우 각 숫자를 이진수로 바꿔서 1의 개수를 세어보자.\n",
      "\n",
      "61은 이진수로 111101. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "52는 110100. 1의 개수는 2개. 2는 짝수.\n",
      "\n",
      "63은 111111. 1의 개수는 6개. 6은 짝수.\n",
      "\n",
      "94는 1011110. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "46은 1011110. 1의 개수는 5개. 5는 홀수.\n",
      "\n",
      "그럼 B 다음의 숫자는 1의 개수가 짝수여야 하나? 그런데 현재 주어진 숫자들 중 마지막이 46인데, 46의 1의 개수는 5개(1011110)로 홀수야. 그럼 다음 숫자는 1의 개수가 홀수여야 하는데, B가 그 다음이니까 B의 1의 개수는 홀수여야 하고, 그 다음 숫자는 짝수여야 하는 식이겠지. 그런데 이게 맞는지 모르겠다. 왜냐하면 이 패턴이 연속된 것인지 확인이 필요해.\n",
      "\n",
      "하지만 이 방법으로는 B를 찾기 어려울 수도 있으니 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 숫자를 9로 나눈 나머지가 어떤 패턴을 이루는지 보는 건 어떨까? 예를 들어, 61 ÷9는 6*9=54, 나머지 7. 52는 5*9=45, 나머지 7. 63은 63으로 나머지 0. 94는 9*10=90, 나머지 4. 46은 4*9=36, 나머지 8. 그럼 B는 9로 나눈 나머지가 어떤 특정한 패턴을 가져야 할까? 예를 들어, 7,7,0,4,8, ... 이런 나머지들이 어떤 규칙이 있는지 보면, 7,7,0,4,8... 이걸 보면 7,7은 2번 반복되고, 0,4,8이 오는 것 같아. 그런데 이 패턴이 2개씩 반복되는 것 같진 않고, 5개의 숫자가 주어졌으니 6번째 숫자의 나머지가 무엇인지 예측해야 해. \n",
      "\n",
      "하지만 이 방법도 확실하지 않아. 다른 방법을 찾아야 할 것 같다.\n",
      "\n",
      "또 다른 가능성은 각 숫자를 7로 나눈 나머지일 수도 있겠다. 61 ÷7은 8*7=56, 나머지 5. 52는 7*7=49, 나머지 3. 63은 9*7=63, 나머지 0. 94는 13*7=91, 나머지 3. 46은 6*7=42, 나머지 4. 그럼 B는 7로 나눈 나머지가 어떤 패턴을 이루는지 보는 거야. 나머지들은 5,3,0,3,4, ?... 이걸 보면 3이 두 번 나오고, 0,3,4가 오는 것 같아. 하지만 이 패턴이 명확하지 않아. 예를 들어, 3,0,3,4, ... 다음이 무엇인지 알 수 없어.\n",
      "\n",
      "아니면 각 숫자를 5로 나눈 나머지? 61은 1, 52는 2, 63은 3, 94는 4, 46은 1. B는 5로 나눈 나머지가 1,2,3,4,1,... 이런 식이라면 아무런 규칙이 없어 보여. 이 방법도 별로인 것 같다.\n",
      "\n",
      "다른 접근 방법이 필요해. 아마도 각 숫자 사이의 차이가 특정한 수열을 이루는 것일 수도 있어. 예를 들어, 61에서 52는 -9, 52에서 63은 +11, 63에서 94는 +31, 94에서 46은 -48. 이 차이들의 수열은 -9, +11, +31, -48. 이 차이들의 패턴을 찾아보자.\n",
      "\n",
      "차이들의 수열: -9, 11, 31, -48. 이 수열의 규칙을 찾아야 해. 예를 들어, 각 차이가 이전 차이에 어떤 연산을 적용한 것일 수 있겠지.\n",
      "\n",
      "-9에서 11로 갈 때, +20. 11에서 31로 갈 때, +20. 31에서 -48로 갈 때, -79. 이 규칙이 일정하지 않아서 복잡해. 다른 방법을 생각해봐야겠다.\n",
      "\n",
      "아니면 각 차이가 이전 두 차이의 합이나 다른 연산을 통해 나오는지? 예를 들어, 첫 번째 차이(-9)와 두 번째 차이(+11)의 합은 +2. 그 다음 차이(+31)는 -9 + 11 + 31 = 31? 아니면 다른 방식? 이 방법도 잘 모르겠다.\n",
      "\n",
      "다른 아이디어: 각 숫자를 10의 자리와 개별적으로 보면? 예를 들어, 61은 6과 1, 52는 5와 2 등. 하지만 이 방법으로는 별다른 패턴이 보이지 않을 것 같아.\n",
      "\n",
      "아니면 각 숫자를 뒤집어서 보면? 예를 들어, 61을 뒤집으면 16, 52는 25, 63은 36, 94는 49, 46은 64. 그런데 이 숫자들이 어떤 규칙이 있는지 보면, 16,25,36,49,64... 이건 모두 완전제곱수네! 4^2,5^2,6^2,7^2,8^2. 그렇다면 B 다음의 숫자도 뒤집으면 완전제곱수가 되어야 하는데, B가 주어진 숫자의 다음이니까, B의 뒤집힌 숫자는 9^2=81이 되어야 할 것 같아. 그렇다면 B는 18이 되어야 해. 왜냐하면 18을 뒤집으면 81이고, 81은 9의 제곱이니까. \n",
      "\n",
      "이 가정을 검증해보자. 주어진 숫자들 61,52,63,94,46, B. 각각을 뒤집으면 16,25,36,49,64, B' (B의 뒤집힌 숫자). 이 숫자들이 4,5,6,7,8,9의 제곱이라면 B'은 9가 되어야 해. 따라서 B는 18이 된다.\n",
      "\n",
      "이게 맞는지 확인해보자. 61 → 16 → 4^2, 52 → 25 →5^2, 63 →36 →6^2, 94 →49 →7^2, 46 →64 →8^2. 그러면 B'이 81 →9^2. 따라서 B는 18이 된다. \n",
      "\n",
      "그렇다면 B=18이 맞는 것 같다. 이 방법이 가장 합리적인 추론인 것 같아. 다른 가능성은 없을까? 예를 들어, 뒤집은 숫자가 제곱수가 되는 것 외에 다른 규칙이 있을 수 있지만, 이 방법이 가장 명확해 보여. \n",
      "\n",
      "그래서 최종 답은 18이 될 것 같다.\n",
      "잠깐, 다시 확인해보자. 각 숫자를 뒤집었을 때 4,5,6,7,8,9의 제곱이 되어야 한다. 61 → 16 (4²), 52 →25 (5²), 63 →36 (6²), 94 →49 (7²), 46 →64 (8²). 그러면 B'은 81 (9²)이 되어야 하므로 B는 18이 된다. 맞는 것 같다. 그럼 답은 18.\n",
      "잠깐, 46을 뒤집으면 64가 되는데, 64는 8²이 맞아. 그러면 B'은 81이 되어야 하므로 B는 18. 이게 맞는 것 같다. 그러면 B=18.\n",
      "Answer: 주어진 숫자열 61, 52, 63, 94, 46, B에서 각 숫자를 뒤집으면 16, 25, 36, 49, 64, B'이 됩니다. 이는 각각 4², 5², 6², 7², 8²에 해당하며, 다음 숫자의 뒤집edList B'은 9²인 81이 됩니다. 따라서 B는 81을 뒤집은 18이 됩니다.\n",
      "\n",
      "$\\boxed{18}$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt += o[0].outputs[0].text\n",
    "stop_token_ids = tok(\"<|im_end|>\")[\"input_ids\"]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=32768,\n",
    "    min_tokens=0,\n",
    "    stop_token_ids=stop_token_ids,\n",
    "    skip_special_tokens=False,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "o = model.generate(\n",
    "    prompt,\n",
    "    sampling_params=sampling_params,\n",
    ")\n",
    "print(prompt + o[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9bd15b-4154-420e-bd5d-a0b2b83dc7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
