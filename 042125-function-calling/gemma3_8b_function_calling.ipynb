{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6875a6-4848-4fc5-97bc-3046b41dc62a",
   "metadata": {},
   "source": [
    "## Gemma3 Function Calling 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0007d7-8e84-4dac-95d7-0a309ee93060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 09:04:56 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import yfinance as yf\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f8ae49-7b9f-4bee-a0c8-d0f49bdebaa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 09:05:17 [config.py:600] This model supports multiple tasks: {'generate', 'classify', 'reward', 'embed', 'score'}. Defaulting to 'generate'.\n",
      "INFO 04-21 09:05:17 [config.py:1780] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 04-21 09:05:22 [core.py:61] Initializing a V1 LLM engine (v0.8.3) with config: model='google/gemma-3-12b-it', speculative_config=None, tokenizer='google/gemma-3-12b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=google/gemma-3-12b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-21 09:05:23 [utils.py:2413] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14ece774f850>\n",
      "INFO 04-21 09:05:24 [parallel_state.py:957] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-21 09:05:24 [cuda.py:221] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 09:05:37 [gpu_model_runner.py:1258] Starting to load model google/gemma-3-12b-it...\n",
      "INFO 04-21 09:05:37 [config.py:3334] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]\n",
      "WARNING 04-21 09:05:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 04-21 09:05:38 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e263cf57854a0d975215235ef271cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 09:07:41 [loader.py:447] Loading weights took 122.68 seconds\n",
      "INFO 04-21 09:07:41 [gpu_model_runner.py:1273] Model loading took 23.3140 GiB and 124.481046 seconds\n",
      "INFO 04-21 09:07:41 [gpu_model_runner.py:1542] Encoder cache will be initialized with a budget of 8192 tokens, and profiled with 32 image items of the maximum feature size.\n",
      "INFO 04-21 09:08:00 [backends.py:416] Using cache directory: /giant-data/user/1111332/.cache/vllm/torch_compile_cache/8a062feeaa/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-21 09:08:00 [backends.py:426] Dynamo bytecode transform time: 14.09 s\n",
      "INFO 04-21 09:08:02 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "INFO 04-21 09:08:35 [monitor.py:33] torch.compile takes 14.09 s in total\n",
      "INFO 04-21 09:08:36 [kv_cache_utils.py:578] GPU KV cache size: 101,792 tokens\n",
      "INFO 04-21 09:08:36 [kv_cache_utils.py:581] Maximum concurrency for 131,072 tokens per request: 0.78x\n",
      "INFO 04-21 09:09:21 [gpu_model_runner.py:1608] Graph capturing finished in 46 secs, took 2.80 GiB\n",
      "INFO 04-21 09:09:22 [core.py:162] init engine (profile, create kv cache, warmup model) took 100.08 seconds\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 초기화\n",
    "MODEL_ID = \"google/gemma-3-12b-it\"\n",
    "model = LLM(MODEL_ID, tensor_parallel_size=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebb807e-f048-4165-be0d-adefb5a32d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링 파라미터 설정 - Gemma 3에 맞게 stop token 변경\n",
    "sampling_params_func_call = SamplingParams(\n",
    "    max_tokens=256, temperature=0.0, stop=[\"<end_of_turn>\"], skip_special_tokens=False\n",
    ")\n",
    "sampling_params_text = SamplingParams(\n",
    "    max_tokens=512, temperature=0.1, top_p=0.95, stop=[\"<end_of_turn>\"], skip_special_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f83df8-f500-4d7c-be13-917a4f45ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOSPI 주식 정보\n",
    "KOSPI_TICKER_MAP = {\n",
    "    \"SK텔레콤\": \"017670.KS\", \"삼성전자\": \"005930.KS\", \"SK하이닉스\": \"000660.KS\",\n",
    "    \"현대차\": \"005380.KS\", \"기아\": \"000270.KS\", \"LG에너지솔루션\": \"373220.KS\",\n",
    "    \"NAVER\": \"035420.KS\", \"카카오\": \"035720.KS\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b1aa62-0966-44fa-9699-fb1f11f585ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구(함수) 정의\n",
    "TOOLS = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_kospi_stock_info\",\n",
    "        \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"stock_name_or_code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"stock_name_or_code\"]\n",
    "        }\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1451907-9c6f-46df-b366-359f0c3a0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주가 조회\n",
    "def get_kospi_stock_info(stock_name_or_code: str) -> str:\n",
    "    \n",
    "    name_or_code = stock_name_or_code.strip()\n",
    "    ticker_symbol = None\n",
    "\n",
    "    if re.fullmatch(r'\\d{6}', name_or_code):\n",
    "        ticker_symbol = name_or_code + \".KS\"\n",
    "    elif name_or_code in KOSPI_TICKER_MAP:\n",
    "        ticker_symbol = KOSPI_TICKER_MAP[name_or_code]\n",
    "    else:\n",
    "        ticker_symbol = name_or_code + \".KS\"\n",
    "\n",
    "    stock = yf.Ticker(ticker_symbol)\n",
    "    stock_info = stock.info\n",
    "\n",
    "    current_price = stock_info.get('currentPrice')\n",
    "    previous_close = stock_info.get('previousClose')\n",
    "\n",
    "    price_to_use = current_price if current_price is not None else previous_close\n",
    "    price_display = round(price_to_use, 2) if price_to_use is not None else \"정보 없음\"\n",
    "    previous_close_display = round(previous_close, 2) if previous_close is not None else \"정보 없음\"\n",
    "\n",
    "    result = {\n",
    "        \"ticker\": ticker_symbol,\n",
    "        \"stock_name\": stock_info.get('shortName', name_or_code),\n",
    "        \"current_price\": price_display,\n",
    "        \"previous_close\": previous_close_display,\n",
    "        \"currency\": stock_info.get('currency', 'KRW')\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255d19c4-d4da-4965-9d43-585ff6ff9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 호출 파싱\n",
    "def parse_tool_calls(output_text: str):\n",
    "\n",
    "    call = re.search(r'\\[(\\w+\\(.*?\\))\\]', output_text)\n",
    "    if not call:\n",
    "        print(\"함수 호출 문자열 '[]'을 찾을 수 없음\")\n",
    "        return None, None\n",
    "\n",
    "    func_match = re.match(r'(\\w+)\\((.*?)\\)', call.group(1))\n",
    "    if not func_match:\n",
    "        print(\"함수 형식이 올바르지 않음\")\n",
    "        return None, None\n",
    "\n",
    "    func_name, params_str = func_match.groups()\n",
    "\n",
    "    params = dict(re.findall(r\"(\\w+)='([^']*)'\", params_str))\n",
    "    return func_name, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad610790-3f7a-4dc7-9ef6-0f8af845279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인 쿼리 처리 함수\n",
    "def query_kospi_info(query: str):\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # 1단계 System 프롬프트 작성\n",
    "    system_msg = f\"\"\"You are a helpful assistant.\n",
    "Current Date: {current_date}\n",
    "You have access to functions. If you decide to invoke any of the function(s),\n",
    "you MUST put it in the format of\n",
    "[func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
    "You SHOULD NOT include any other text in the response if you call a function\n",
    "{json.dumps(TOOLS, indent=2, ensure_ascii=False)}\n",
    "\"\"\"\n",
    "    print(f\"\\n### 1단계 System 프롬프트 작성 : \\n{system_msg}\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    print(f\"### 2단계 Chat 기반 메시지 작성 : {messages}\")\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "    print(f\"\\n### 3단계 함수 선택을 위한 프롬프트 구성 : \\n{prompt}\")\n",
    "\n",
    "    outputs = model.generate([prompt], sampling_params_func_call)\n",
    "    func_call_text = outputs[0].outputs[0].text\n",
    "    print(f\"\\n### 4단계 함수 호출을 위한 LLM 응답 : \\n{func_call_text}\")\n",
    "\n",
    "    func_name, params = parse_tool_calls(func_call_text)\n",
    "    if not func_name:\n",
    "        return re.sub(r\"<end_of_turn>\\s*$\", \"\", func_call_text).strip()\n",
    "\n",
    "    if func_name == \"get_kospi_stock_info\" and \"stock_name_or_code\" in params:\n",
    "        function_result = get_kospi_stock_info(params[\"stock_name_or_code\"])\n",
    "        print(f\"\\n### 5단계 함수 호출 내용 파싱 및 실행 결과: \\n{function_result}\")\n",
    "    else:\n",
    "        err = {\"error\": f\"지원하지 않는 함수({func_name}) 또는 필수 파라미터 누락\"}\n",
    "        function_result = json.dumps(err, ensure_ascii=False)\n",
    "        print(f\"지원하지 않는 함수 호출({func_name}) 또는 필수 파라미터 누락\")\n",
    "\n",
    "    if not function_result:\n",
    "        print(\"함수 실행 결과가 없어 응답 생성을 중단.\")\n",
    "        return \"함수 실행 중 문제가 발생하여 답변을 생성할 수 없음\"\n",
    "\n",
    "    followup_prompt = (\n",
    "        f\"I called the function {func_name} with parameters {params}.\\n\"\n",
    "        f\"The function returned the following result:\\n{function_result}\\n\\n\"\n",
    "        f'Based on this information, please provide a helpful response to the user\\'s query: \"{query}\".'\n",
    "    )\n",
    "    final_messages = messages + [\n",
    "        {\"role\": \"assistant\", \"content\": func_call_text},\n",
    "        {\"role\": \"user\", \"content\": followup_prompt},\n",
    "    ]\n",
    "    final_prompt = tokenizer.apply_chat_template(\n",
    "        final_messages, add_generation_prompt=True, tokenize=False\n",
    "    )\n",
    "    print(f\"\\n### 6단계 함수 호출 내용 및 메시지 추가 (최종 프롬프트): \\n{final_prompt}\")\n",
    "\n",
    "    outputs = model.generate([final_prompt], sampling_params_text)\n",
    "    final_text = outputs[0].outputs[0].text\n",
    "    print(\"\\n### 7단계 최종 응답:\")\n",
    "    return re.sub(r\"<end_of_turn>\\s*$\", \"\", final_text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8dad10-8849-41ff-a823-1a11e8e134c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " 질문: SK텔레콤의 주가를 알려줘\n",
      "==========================================\n",
      "\n",
      "### 1단계 System 프롬프트 작성 : \n",
      "You are a helpful assistant.\n",
      "Current Date: 2025-04-21\n",
      "You have access to functions. If you decide to invoke any of the function(s),\n",
      "you MUST put it in the format of\n",
      "[func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
      "You SHOULD NOT include any other text in the response if you call a function\n",
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"get_kospi_stock_info\",\n",
      "      \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"stock_name_or_code\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"stock_name_or_code\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "### 2단계 Chat 기반 메시지 작성 : [{'role': 'system', 'content': 'You are a helpful assistant.\\nCurrent Date: 2025-04-21\\nYou have access to functions. If you decide to invoke any of the function(s),\\nyou MUST put it in the format of\\n[func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\\nYou SHOULD NOT include any other text in the response if you call a function\\n[\\n  {\\n    \"type\": \"function\",\\n    \"function\": {\\n      \"name\": \"get_kospi_stock_info\",\\n      \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\\n      \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n          \"stock_name_or_code\": {\\n            \"type\": \"string\",\\n            \"description\": \"주식 이름(예: \\'SK텔레콤\\') 또는 종목 코드(예: \\'017670\\')\"\\n          }\\n        },\\n        \"required\": [\\n          \"stock_name_or_code\"\\n        ]\\n      }\\n    }\\n  }\\n]\\n'}, {'role': 'user', 'content': 'SK텔레콤의 주가를 알려줘'}]\n",
      "\n",
      "### 3단계 함수 선택을 위한 프롬프트 구성 : \n",
      "<bos><start_of_turn>user\n",
      "You are a helpful assistant.\n",
      "Current Date: 2025-04-21\n",
      "You have access to functions. If you decide to invoke any of the function(s),\n",
      "you MUST put it in the format of\n",
      "[func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
      "You SHOULD NOT include any other text in the response if you call a function\n",
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"get_kospi_stock_info\",\n",
      "      \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"stock_name_or_code\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"stock_name_or_code\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "SK텔레콤의 주가를 알려줘<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, est. speed input: 474.95 toks/s, output: 39.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 4단계 함수 호출을 위한 LLM 응답 : \n",
      "[get_kospi_stock_info(stock_name_or_code='SK텔레콤')]\n",
      "\n",
      "### 5단계 함수 호출 내용 파싱 및 실행 결과: \n",
      "{\"ticker\": \"017670.KS\", \"stock_name\": \"SKTelecom\", \"current_price\": 57700.0, \"previous_close\": 57900.0, \"currency\": \"KRW\"}\n",
      "\n",
      "### 6단계 함수 호출 내용 및 메시지 추가 (최종 프롬프트): \n",
      "<bos><start_of_turn>user\n",
      "You are a helpful assistant.\n",
      "Current Date: 2025-04-21\n",
      "You have access to functions. If you decide to invoke any of the function(s),\n",
      "you MUST put it in the format of\n",
      "[func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
      "You SHOULD NOT include any other text in the response if you call a function\n",
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"get_kospi_stock_info\",\n",
      "      \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"stock_name_or_code\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"stock_name_or_code\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "SK텔레콤의 주가를 알려줘<end_of_turn>\n",
      "<start_of_turn>model\n",
      "[get_kospi_stock_info(stock_name_or_code='SK텔레콤')]<end_of_turn>\n",
      "<start_of_turn>user\n",
      "I called the function get_kospi_stock_info with parameters {'stock_name_or_code': 'SK텔레콤'}.\n",
      "The function returned the following result:\n",
      "{\"ticker\": \"017670.KS\", \"stock_name\": \"SKTelecom\", \"current_price\": 57700.0, \"previous_close\": 57900.0, \"currency\": \"KRW\"}\n",
      "\n",
      "Based on this information, please provide a helpful response to the user's query: \"SK텔레콤의 주가를 알려줘\".<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, est. speed input: 482.98 toks/s, output: 47.86 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 7단계 최종 응답:\n",
      "\n",
      " 답변: SK텔레콤(017670.KS)의 현재 주가는 57,700원입니다. 이전 거래일 종가는 57,900원이었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    queries = [\n",
    "        \"SK텔레콤의 주가를 알려줘\",\n",
    "#        \"삼성전자 현재가 얼마야?\",\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"\\n========================================\")\n",
    "        print(f\" 질문: {query}\")\n",
    "        print(f\"==========================================\")\n",
    "        response = query_kospi_info(query)\n",
    "        print(f\"\\n 답변: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e81a61-f19d-45a4-9800-a89daa0d7d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
