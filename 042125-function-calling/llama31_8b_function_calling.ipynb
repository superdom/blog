{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5dfb7a-2e46-4f85-b602-e74f79fa342b",
   "metadata": {},
   "source": [
    "## Llama 3.1 Function Calling 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b7c9ff-a4ba-4cb8-9dd5-01272950b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 08:59:39 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import yfinance as yf\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e19c261-2df3-4903-83a4-7929e8d704c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 08:59:58 [config.py:600] This model supports multiple tasks: {'reward', 'score', 'classify', 'generate', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 04-21 08:59:58 [config.py:1780] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 04-21 09:00:00 [core.py:61] Initializing a V1 LLM engine (v0.8.3) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-21 09:00:01 [utils.py:2413] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14e3a7de6350>\n",
      "INFO 04-21 09:00:03 [parallel_state.py:957] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-21 09:00:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 04-21 09:00:03 [gpu_model_runner.py:1258] Starting to load model meta-llama/Llama-3.1-8B-Instruct...\n",
      "WARNING 04-21 09:00:04 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 04-21 09:00:04 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc9155d96d044afa30dac809d18fcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 09:01:26 [loader.py:447] Loading weights took 81.50 seconds\n",
      "INFO 04-21 09:01:27 [gpu_model_runner.py:1273] Model loading took 14.9889 GiB and 83.196120 seconds\n",
      "INFO 04-21 09:01:35 [backends.py:416] Using cache directory: /giant-data/user/1111332/.cache/vllm/torch_compile_cache/839addc9a7/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-21 09:01:35 [backends.py:426] Dynamo bytecode transform time: 8.13 s\n",
      "INFO 04-21 09:01:36 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "INFO 04-21 09:01:45 [monitor.py:33] torch.compile takes 8.13 s in total\n",
      "INFO 04-21 09:01:47 [kv_cache_utils.py:578] GPU KV cache size: 417,568 tokens\n",
      "INFO 04-21 09:01:47 [kv_cache_utils.py:581] Maximum concurrency for 131,072 tokens per request: 3.19x\n",
      "INFO 04-21 09:02:23 [gpu_model_runner.py:1608] Graph capturing finished in 36 secs, took 1.61 GiB\n",
      "INFO 04-21 09:02:23 [core.py:162] init engine (profile, create kv cache, warmup model) took 56.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 초기화\n",
    "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "model = LLM(MODEL_ID, tensor_parallel_size=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6d7942-5aa7-48e7-93f9-4e845b7d4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링 파라미터 설정 - llama3.1 에 맞게 stop token 변경\n",
    "sampling_params_func_call = SamplingParams(\n",
    "    max_tokens=256, temperature=0.0, stop=[\"<|im_end|>\"], skip_special_tokens=False\n",
    ")\n",
    "sampling_params_text = SamplingParams(\n",
    "    max_tokens=512, temperature=0.1, top_p=0.95, stop=[\"<|im_end|>\"], skip_special_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf4af3e-88ca-422a-8fc2-f47102a5adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOSPI 주식 정보\n",
    "KOSPI_TICKER_MAP = {\n",
    "    \"SK텔레콤\": \"017670.KS\", \"삼성전자\": \"005930.KS\", \"SK하이닉스\": \"000660.KS\",\n",
    "    \"현대차\": \"005380.KS\", \"기아\": \"000270.KS\", \"LG에너지솔루션\": \"373220.KS\",\n",
    "    \"NAVER\": \"035420.KS\", \"카카오\": \"035720.KS\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca74ab8-e9b7-48ce-9350-ecf166a657be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구(함수) 정의\n",
    "TOOLS = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_kospi_stock_info\",\n",
    "        \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"stock_name_or_code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"stock_name_or_code\"]\n",
    "        }\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cc0e03-a20b-421a-8f06-696affc9f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주가 조회\n",
    "def get_kospi_stock_info(stock_name_or_code: str) -> str:\n",
    "\n",
    "    name_or_code = stock_name_or_code.strip()\n",
    "    ticker_symbol = None\n",
    "\n",
    "    if re.fullmatch(r'\\d{6}', name_or_code):\n",
    "        ticker_symbol = name_or_code + \".KS\"\n",
    "    elif name_or_code in KOSPI_TICKER_MAP:\n",
    "        ticker_symbol = KOSPI_TICKER_MAP[name_or_code]\n",
    "    else:\n",
    "        ticker_symbol = name_or_code + \".KS\"\n",
    "\n",
    "    stock = yf.Ticker(ticker_symbol)\n",
    "    stock_info = stock.info\n",
    "\n",
    "    current_price = stock_info.get('currentPrice')\n",
    "    previous_close = stock_info.get('previousClose')\n",
    "\n",
    "    price_to_use = current_price if current_price is not None else previous_close\n",
    "    price_display = round(price_to_use, 2) if price_to_use is not None else \"정보 없음\"\n",
    "    previous_close_display = round(previous_close, 2) if previous_close is not None else \"정보 없음\"\n",
    "\n",
    "    result = {\n",
    "        \"ticker\": ticker_symbol,\n",
    "        \"stock_name\": stock_info.get('shortName', name_or_code),\n",
    "        \"current_price\": price_display,\n",
    "        \"previous_close\": previous_close_display,\n",
    "        \"currency\": stock_info.get('currency', 'KRW')\n",
    "    }\n",
    "\n",
    "    return json.dumps(result, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab7da4f-eec8-4ac9-af66-8d85e7034f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 호출 파싱\n",
    "# JSON 유효성 검사\n",
    "def parse_tool_calls(output_text: str):\n",
    "\n",
    "    cleaned_output = output_text.strip()\n",
    "    json.loads(cleaned_output)\n",
    "\n",
    "    return {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": cleaned_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c4a3bc-e3be-4384-9189-91cb6166ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython 메시지 생성 함수\n",
    "def create_ipython_message(tool_result_dict: dict):\n",
    "    return {\n",
    "        \"role\": \"ipython\",\n",
    "        \"content\": {\n",
    "            \"output\": tool_result_dict\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870dfb89-3b84-495b-abb2-bc0dfe1c89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인 쿼리 처리 함수\n",
    "def query_kospi_info(query: str):\n",
    "\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    system_message = f\"When you receive a tool call response, use the output to format an answer to the orginal user question. \\n You are a helpful assistant with tool calling capabilities. Current Date: {current_date}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    print(f\"\\n### 1단계 초기 메시지 작성:\\n{messages}\")\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tools=TOOLS, add_generation_prompt=True, tokenize=False)\n",
    "    cleaned_prompt = \"\\n\".join(\n",
    "        line for line in prompt.splitlines() if \"Environment: ipython\" not in line\n",
    "    )\n",
    "    print(f\"\\n### 2단계 함수 선택/응답 생성을 위한 프롬프트 구성:\\n{cleaned_prompt}\")\n",
    "\n",
    "    outputs = model.generate([cleaned_prompt], sampling_params=sampling_params_func_call)\n",
    "    func_call_response_text = outputs[0].outputs[0].text\n",
    "    print(f\"\\n### 3단계 함수 호출/초기 응답을 위한 LLM 응답:\\n{func_call_response_text}\")\n",
    "\n",
    "    assistant_msg = parse_tool_calls(func_call_response_text)\n",
    "    messages.append(assistant_msg)\n",
    "    print(f\"\\n### 4단계 어시스턴트 함수 호출 메시지 추가 후:\\n{messages}\")\n",
    "\n",
    "#    tool_call_content = assistant_msg['content']\n",
    "    tool_call_content = func_call_response_text\n",
    "    print(f\"$$$ check: {tool_call_content}\")\n",
    "    python_tag = \"<|python_tag|>\"\n",
    "    if tool_call_content.startswith(python_tag):\n",
    "        tool_call_content = tool_call_content[len(python_tag):].strip()\n",
    "\n",
    "    tool_data = json.loads(tool_call_content)\n",
    "    tool_params = tool_data.get(\"parameters\")\n",
    "\n",
    "    if tool_params is None or \"stock_name_or_code\" not in tool_params:\n",
    "         raise ValueError(\"LLM response did not contain valid 'parameters' or 'stock_name_or_code'\")\n",
    "\n",
    "    stock_name_or_code = tool_params[\"stock_name_or_code\"]\n",
    "    function_result_json_str = get_kospi_stock_info(stock_name_or_code)\n",
    "\n",
    "    function_result_dict = json.loads(function_result_json_str)\n",
    "    print(f\"\\n### 5단계 함수 실행 결과:\\n{function_result_dict}\")\n",
    "\n",
    "    ipython_msg = create_ipython_message(function_result_dict)\n",
    "    messages.append(ipython_msg)\n",
    "    print(f\"\\n### 5.1단계 Tool 결과('ipython' role) 메시지 추가 후:\\n{messages}\")\n",
    "\n",
    "    final_prompt = tokenizer.apply_chat_template(messages, tools=TOOLS, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "    print(f\"\\n### 6단계 최종 응답 생성을 위한 프롬프트:\\n{final_prompt}\")\n",
    "    \n",
    "    outputs = model.generate([final_prompt], sampling_params=sampling_params_text)\n",
    "    final_response = outputs[0].outputs[0].text\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5655026a-5141-4ca1-9eab-6ab10697b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " 질문: Tell me the stock price of SK텔레콤\n",
      "========================================\n",
      "\n",
      "### 1단계 초기 메시지 작성:\n",
      "[{'role': 'system', 'content': 'When you receive a tool call response, use the output to format an answer to the orginal user question. \\n You are a helpful assistant with tool calling capabilities. Current Date: 2025-04-21'}, {'role': 'user', 'content': 'Tell me the stock price of SK텔레콤'}]\n",
      "\n",
      "### 2단계 함수 선택/응답 생성을 위한 프롬프트 구성:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "When you receive a tool call response, use the output to format an answer to the orginal user question. \n",
      " You are a helpful assistant with tool calling capabilities. Current Date: 2025-04-21<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
      "\n",
      "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.Do not use variables.\n",
      "\n",
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "        \"name\": \"get_kospi_stock_info\",\n",
      "        \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"stock_name_or_code\": {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"stock_name_or_code\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Tell me the stock price of SK텔레콤<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s, est. speed input: 736.34 toks/s, output: 75.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 3단계 함수 호출/초기 응답을 위한 LLM 응답:\n",
      "{\"name\": \"get_kospi_stock_info\", \"parameters\": {\"stock_name_or_code\": \"SK텔레콤\"}}\n",
      "\n",
      "### 4단계 어시스턴트 함수 호출 메시지 추가 후:\n",
      "[{'role': 'system', 'content': 'When you receive a tool call response, use the output to format an answer to the orginal user question. \\n You are a helpful assistant with tool calling capabilities. Current Date: 2025-04-21'}, {'role': 'user', 'content': 'Tell me the stock price of SK텔레콤'}, {'role': 'assistant', 'content': '{\"name\": \"get_kospi_stock_info\", \"parameters\": {\"stock_name_or_code\": \"SK텔레콤\"}}'}]\n",
      "$$$ check: {\"name\": \"get_kospi_stock_info\", \"parameters\": {\"stock_name_or_code\": \"SK텔레콤\"}}\n",
      "\n",
      "### 5단계 함수 실행 결과:\n",
      "{'ticker': '017670.KS', 'stock_name': 'SKTelecom', 'current_price': 57700.0, 'previous_close': 57900.0, 'currency': 'KRW'}\n",
      "\n",
      "### 5.1단계 Tool 결과('ipython' role) 메시지 추가 후:\n",
      "[{'role': 'system', 'content': 'When you receive a tool call response, use the output to format an answer to the orginal user question. \\n You are a helpful assistant with tool calling capabilities. Current Date: 2025-04-21'}, {'role': 'user', 'content': 'Tell me the stock price of SK텔레콤'}, {'role': 'assistant', 'content': '{\"name\": \"get_kospi_stock_info\", \"parameters\": {\"stock_name_or_code\": \"SK텔레콤\"}}'}, {'role': 'ipython', 'content': {'output': {'ticker': '017670.KS', 'stock_name': 'SKTelecom', 'current_price': 57700.0, 'previous_close': 57900.0, 'currency': 'KRW'}}}]\n",
      "\n",
      "### 6단계 최종 응답 생성을 위한 프롬프트:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Environment: ipython\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "When you receive a tool call response, use the output to format an answer to the orginal user question. \n",
      " You are a helpful assistant with tool calling capabilities. Current Date: 2025-04-21<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
      "\n",
      "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.Do not use variables.\n",
      "\n",
      "{\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "        \"name\": \"get_kospi_stock_info\",\n",
      "        \"description\": \"특정 KOSPI 주식의 현재 가격 및 기본 정보를 가져옵니다.\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"stock_name_or_code\": {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"주식 이름(예: 'SK텔레콤') 또는 종목 코드(예: '017670')\"\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"stock_name_or_code\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Tell me the stock price of SK텔레콤<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"name\": \"get_kospi_stock_info\", \"parameters\": {\"stock_name_or_code\": \"SK텔레콤\"}}<|eot_id|><|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\"output\": {\"ticker\": \"017670.KS\", \"stock_name\": \"SKTelecom\", \"current_price\": 57700.0, \"previous_close\": 57900.0, \"currency\": \"KRW\"}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, est. speed input: 1294.16 toks/s, output: 63.81 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 답변: The current price of SK텔레콤 is 57,700 KRW.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    queries = [\n",
    "        \"Tell me the stock price of SK텔레콤\",\n",
    "#        \"현대차 주가 알려줘\"\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"\\n========================================\")\n",
    "        print(f\" 질문: {query}\")\n",
    "        print(f\"========================================\")\n",
    "        response = query_kospi_info(query)\n",
    "        print(f\"\\n 답변: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13710853-b5f4-47fe-be76-27c5d6974ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
